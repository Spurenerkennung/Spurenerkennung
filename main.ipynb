{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_measurements = {}\n",
    "\n",
    "def start_time_measurement(eventName):\n",
    "    add = False\n",
    "    if eventName not in time_measurements:\n",
    "        time_measurements[eventName] = {\n",
    "            \"name\": eventName,\n",
    "            \"start\": [],\n",
    "            \"end\": [],\n",
    "            \"count\": 0\n",
    "        }\n",
    "        add = True\n",
    "    elif len(time_measurements[eventName][\"start\"]) > len(time_measurements[eventName][\"end\"]):\n",
    "        print(f\"Time measure error: Event '{eventName}' not finished before reassignment!\")\n",
    "    else:\n",
    "       add = True\n",
    "    \n",
    "    #start measurement as late as possible\n",
    "    if add:\n",
    "        time_measurements[eventName][\"start\"].append(time.perf_counter_ns())\n",
    "\n",
    "def end_time_measurement(eventName):\n",
    "    #end measurement as fast as possible\n",
    "    temp_time = time.perf_counter_ns()\n",
    "    if eventName not in time_measurements:\n",
    "        print(f\"Time measure error: Event '{eventName}' not defined!\")\n",
    "    elif len(time_measurements[eventName][\"end\"]) >= len(time_measurements[eventName][\"start\"]):\n",
    "        print(f\"Time measure error: Event '{eventName}' not started before reassignment!\")\n",
    "    else:\n",
    "        time_measurements[eventName][\"end\"].append(temp_time)\n",
    "        time_measurements[eventName][\"count\"] += 1\n",
    "\n",
    "def analyse_time_measurements():\n",
    "    time_measurements_table = PrettyTable([\"Name\", \"Avg. [ms]\", \"Min. [ms]\", \"Max. [ms]\", \"Occurrences [compl.]\"])\n",
    "    time_measurements_table.align[\"Name\"] = \"l\"\n",
    "    time_measurements_table.align[\"Avg. [ms]\"] = \"r\"\n",
    "    time_measurements_table.align[\"Min. [ms]\"] = \"r\"\n",
    "    time_measurements_table.align[\"Max. [ms]\"] = \"r\"\n",
    "    time_measurements_table.align[\"Occurrences [compl.]\"] = \"r\"\n",
    "    for key, event in time_measurements.items():\n",
    "        timings = []\n",
    "        if len(event[\"start\"]) != len(event[\"end\"]):\n",
    "            print(f\"Time measure error: Event '{key}' has different amounts of values for start and end times!\")\n",
    "        else:\n",
    "            #exclude 0 values\n",
    "            for i in range(len(event[\"start\"])):\n",
    "                timing = (event[\"end\"][i] - event[\"start\"][i])\n",
    "                if timing >= 0:\n",
    "                    timing = timing / (1000 * 1000) #convert from ns to ms\n",
    "                    timings.append(timing)\n",
    "\n",
    "            event[\"min\"] = min(timings) \n",
    "            event[\"max\"] = max(timings)\n",
    "            event[\"avg\"] = sum(timings) / len(event[\"start\"])\n",
    "\n",
    "            time_measurements_table.add_row([key, '{0:.2f}'.format(event[\"avg\"]), '{0:.2f}'.format(event[\"min\"]), '{0:.2f}'.format(event[\"max\"]), event[\"count\"]])\n",
    "    print(time_measurements_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kamerakalibrierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of chessboard, minimum error with (7, 6), but there were severe artefacts at the borders (see error calculation at the end)\n",
    "x, y = 9, 6\n",
    "\n",
    "# termination criteria\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((y * x, 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:x, 0:y].T.reshape(-1, 2)\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = []  # 3d point in real world space\n",
    "imgpoints = []  # 2d points in image plane.\n",
    "\n",
    "\n",
    "images = glob.glob(\"./img/Udacity/calib/*.jpg\")\n",
    "for i, fname in enumerate(images):\n",
    "    img = cv.imread(fname)\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chess board corners\n",
    "    ret, corners = cv.findChessboardCorners(gray, (x, y), None)\n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        corners2 = cv.cornerSubPix(\n",
    "            gray, corners, (11, 11), (-1, -1), criteria\n",
    "        )  # improve accuracy of corners\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(\n",
    "    objpoints, imgpoints, gray.shape[::-1], None, None\n",
    ")\n",
    "\n",
    "h, w = img.shape[:2]\n",
    "newcameramtx, roi = cv.getOptimalNewCameraMatrix(mtx, dist, (w, h), 1, (w, h))\n",
    "\n",
    "\n",
    "def undistort_image(img):\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    img_undist = cv.undistort(img, mtx, dist, None, newcameramtx)\n",
    "    # crop the image\n",
    "    x, y, w, h = roi\n",
    "    return img_undist[y : y + h, x : x + w]\n",
    "\n",
    "\n",
    "# ~50% faster than undistort_image()\n",
    "def undistort_image_remap(img):\n",
    "    h, w = img.shape[:2]\n",
    "    mapx, mapy = cv.initUndistortRectifyMap(mtx, dist, None, newcameramtx, (w, h), 5)\n",
    "    dst = cv.remap(img, mapx, mapy, cv.INTER_LINEAR)\n",
    "    # crop the image\n",
    "    x, y, w, h = roi\n",
    "    return dst[y : y + h, x : x + w]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perspektivtransformation\n",
    "\n",
    "Mögliche Performance-verbesserung:\n",
    "\n",
    "- Bild nach warp verkleinern, da ein großteil des Bildes aus wenigen Pixeln entsteht ->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# udacity images\n",
    "src_udacity = np.float32([[191, 628], [531, 404], [1021, 628], [681, 404]])\n",
    "dst_udacity = np.float32([[150, 720], [150, 10], [1000, 720], [1000, 10]])\n",
    "M_warp = cv.getPerspectiveTransform(src_udacity, dst_udacity)\n",
    "M_rewarp = cv.getPerspectiveTransform(dst_udacity, src_udacity)\n",
    "\n",
    "\n",
    "def warp_image_udacity(img):\n",
    "    img = cv.warpPerspective(img, M_warp, (img.shape[1], img.shape[0]))\n",
    "    # image = cv.resize(\n",
    "    #     image, (int(img.shape[1] / 2), int(img.shape[0] / 2))\n",
    "    # )  # resize to half size\n",
    "    return img\n",
    "\n",
    "def rewarp_image_udacity(img):\n",
    "    # image = cv.resize(\n",
    "    #     img, (int(img.shape[1] * 2), int(img.shape[0] * 2))\n",
    "    # ) \n",
    "    # img = cv.warpPerspective(img, M_rewarp, (img.shape[1], img.shape[0]))\n",
    "    img = cv.warpPerspective(img, M_rewarp, (img.shape[1], img.shape[0]), cv.WARP_INVERSE_MAP)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sliding Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwindows = 50\n",
    "margin = 50\n",
    "def sliding_windows(frame, window_width=200, minimum_whites=30, show_windows=False):\n",
    "    # Histogram for image\n",
    "    hist = np.sum(frame[frame.shape[0]//2:, :], axis=0)\n",
    "        \n",
    "    # Take peaks from left and right side of histogramm for starting points and add half margin\n",
    "    mid = np.int32(hist.shape[0] // 2)\n",
    "    leftx_start = np.argmax(hist[:mid]) - window_width // 2\n",
    "    rightx_start = np.argmax(hist[mid:]) + mid + window_width // 2\n",
    "    # Window height based on number of windows\n",
    "    window_height = np.int32(frame.shape[0] // nwindows)\n",
    "    \n",
    "    # Calc points that are not zero in images\n",
    "    nonzero = frame.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    # Initialize current positions for windows\n",
    "    leftx_current = leftx_start\n",
    "    rightx_current = rightx_start\n",
    "\n",
    "    # Initialize values to be returned -> centers of windows\n",
    "    lefts_good = np.empty(shape=(1,1), dtype=int)\n",
    "    rights_good = np.empty(shape=(1,1), dtype=int)\n",
    "\n",
    "    # Go through every window\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = frame.shape[0] - (window + 1) * window_height\n",
    "        win_y_high = frame.shape[0] - window*window_height\n",
    "        y_mid = (win_y_low + win_y_high) // 2\n",
    "        \n",
    "        # Calculate boundaries of the window\n",
    "        win_xleft_low = leftx_current - window_width  \n",
    "        win_xleft_high = leftx_current + window_width  \n",
    "        win_xright_low =  rightx_current - window_width \n",
    "        win_xright_high = rightx_current + window_width  \n",
    "        \n",
    "        # Identify the pixels that are not zero within window\n",
    "        left_inds = ((nonzeroy >= win_y_low ) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        right_inds = ((nonzeroy >= win_y_low ) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # If more than minimum pixels are found -> recenter next window\n",
    "        if len(left_inds) > minimum_whites:\n",
    "            leftx_current = np.int32(np.mean(nonzerox[left_inds]))\n",
    "            lefts_good = np.append(lefts_good, leftx_current)\n",
    "            if show_windows:\n",
    "                cv.rectangle(frame, (leftx_current - margin, win_y_low),(leftx_current + margin, win_y_high),(255, 255, 255), 2)\n",
    "        else:\n",
    "            lefts_good = np.append(lefts_good, None)\n",
    "        if len(right_inds) > minimum_whites:\n",
    "            rightx_current = np.int32(np.mean(nonzerox[right_inds]))\n",
    "            rights_good = np.append(rights_good, rightx_current)\n",
    "            if show_windows:\n",
    "                cv.rectangle(frame, (rightx_current - margin, win_y_low),(rightx_current + margin, win_y_high),(255, 255, 255), 2)\n",
    "        else:\n",
    "            rights_good = np.append(rights_good, None)\n",
    "\n",
    "    return mid, lefts_good, rights_good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PolyLines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawPolyLines(frame, left_pts, right_pts):\n",
    "    y = np.linspace(len(frame), 0, nwindows+1).astype(int)\n",
    "    left_line = np.array(list(zip(left_pts[1:], y)))\n",
    "    right_line = np.array(list(zip(right_pts[1:], y)))\n",
    "\n",
    "    cv.polylines(frame, [left_line], 0, (255,255,255), 2)\n",
    "    cv.polylines(frame, [right_line], 0, (255,255,255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lane_detection(frame, flag=False):\n",
    "    frame = cv.GaussianBlur(frame, (5, 5), 0)\n",
    "    frame_hls = cv.cvtColor(frame, cv.COLOR_BGR2HLS)\n",
    "    white_lower = (0, 180, 0)\n",
    "    white_upper = (254, 254, 254)\n",
    "    if flag:\n",
    "        white_lower = (0, 180, 0)\n",
    "        white_upper = (240, 240, 240)\n",
    "\n",
    "    white_mask = cv.inRange(frame_hls, white_lower, white_upper)\n",
    "\n",
    "    frame_lab = cv.cvtColor(frame, cv.COLOR_BGR2LAB)\n",
    "    yellow_mask = cv.inRange(frame_lab, (150, 100, 140), (255, 140, 200))\n",
    "\n",
    "    combined_mask = cv.bitwise_or(white_mask, yellow_mask)\n",
    "\n",
    "    redImg = np.zeros(frame.shape, frame.dtype)\n",
    "    redImg[:,:] = (0, 0, 255)\n",
    "    redMask = cv.bitwise_and(redImg, redImg, mask=yellow_mask)\n",
    "\n",
    "    greenImg = np.zeros(frame.shape, frame.dtype)\n",
    "    greenImg[:,:] = (0, 255, 0)\n",
    "    greenMask = cv.bitwise_and(greenImg, greenImg, mask=white_mask)\n",
    "\n",
    "    masks = redMask + greenMask\n",
    "    # if not flag:\n",
    "    #     frame_luv = cv.cvtColor(frame, cv.COLOR_BGR2LUV)\n",
    "    #     yellow_mask2 = cv.inRange(frame_luv, (150, 100, 150), (255, 140, 200))\n",
    "    #     combined_yellow = cv.bitwise_and(yellow_mask, yellow_mask2)\n",
    "    #     combined_mask = cv.bitwise_or(white_mask, combined_yellow)\n",
    "    #     blueImg = np.zeros(frame.shape, frame.dtype)\n",
    "    #     blueImg[:,:] = (255, 0, 0)\n",
    "    #     blueMask = cv.bitwise_and(blueImg, blueImg, mask=yellow_mask2)\n",
    "    #     masks = masks + blueMask\n",
    "\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE, (7, 3))\n",
    "    lanes = cv.morphologyEx(frame_hls[:, :, 1], cv.MORPH_TOPHAT, kernel)\n",
    "\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_RECT, (13, 13))\n",
    "    lanes_yellow = cv.morphologyEx(frame_lab[:, :, 2], cv.MORPH_TOPHAT, kernel)\n",
    "\n",
    "    ret, lanes_yellow = cv.threshold(lanes_yellow, thresh=2, maxval=255, type=cv.THRESH_BINARY)\n",
    "    lanes_yellow = cv.morphologyEx(lanes_yellow, cv.MORPH_OPEN, np.array([[0,1,0],[1,1,1],[0,1,0]], 'uint8'), iterations=4)\n",
    "\n",
    "    lanes = cv.morphologyEx(frame_hls[:, :, 1], \n",
    "                              cv.MORPH_BLACKHAT,\n",
    "                              kernel)\n",
    "\n",
    "    ret, lanes = cv.threshold(lanes, thresh=5, maxval=255, type=cv.THRESH_BINARY)\n",
    "\n",
    "    combined_mask = cv.bitwise_or(combined_mask, lanes_yellow)\n",
    "\n",
    "    combined_mask = cv.morphologyEx(combined_mask, cv.MORPH_OPEN, np.array([[0,1,0],[1,1,1],[0,1,0]], 'uint8'), iterations=2)\n",
    "    # combined_mask = cv.Canny(combined_mask, 50, 150)\n",
    "    frame = cv.bitwise_and(frame, frame, mask=combined_mask)\n",
    "    frame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    cv.imshow(\"Masks\", masks)\n",
    "    cv.imshow(\"TOP_HAT_LANES_YELLOW\", lanes_yellow)\n",
    "    cv.imshow(\"BLACK_HAT_LANES\", lanes)\n",
    "    cv.imshow(\"Final\", combined_mask)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_Brightness(frame):\n",
    "    frame_hsv = cv.cvtColor(frame, cv.COLOR_BGR2HSV)\n",
    "    brightness = frame_hsv[...,2].mean()\n",
    "    brightness_upper_limit = 115\n",
    "    brightness_lower_limit = 85\n",
    "    flag = False\n",
    "    if brightness > brightness_upper_limit:\n",
    "        hsv = cv.cvtColor(frame, cv.COLOR_BGR2HSV)\n",
    "        h, s, v = cv.split(hsv)\n",
    "        \n",
    "        lim = round(0 + brightness - brightness_upper_limit)\n",
    "        v[v < lim] = 0\n",
    "        v[v >= lim] -= lim\n",
    "\n",
    "        final_hsv = cv.merge((h, s, v))\n",
    "        frame = cv.cvtColor(final_hsv, cv.COLOR_HSV2BGR)\n",
    "        flag = True\n",
    "    \n",
    "    if brightness < brightness_lower_limit:\n",
    "        hsv = cv.cvtColor(frame, cv.COLOR_BGR2HSV)\n",
    "        h, s, v = cv.split(hsv)\n",
    "        \n",
    "        lim = round(255 + brightness_lower_limit - brightness)\n",
    "        v[v > lim] = 255\n",
    "        v[v <= lim] += lim\n",
    "\n",
    "        final_hsv = cv.merge((h, s, v))\n",
    "        frame = cv.cvtColor(final_hsv, cv.COLOR_HSV2BGR)\n",
    "        flag = False\n",
    "\n",
    "    return frame, flag, brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_two_color_images(image1, image2):\n",
    "    foreground, background = image1.copy(), image2.copy()\n",
    "    \n",
    "    foreground_height = foreground.shape[0]\n",
    "    foreground_width = foreground.shape[1]\n",
    "    alpha =0.5\n",
    "    \n",
    "    # do composite on the upper-left corner of the background image.\n",
    "    blended_portion = cv.addWeighted(foreground,\n",
    "                alpha,\n",
    "                background[:foreground_height,:foreground_width,:],\n",
    "                1 - alpha,\n",
    "                0,\n",
    "                background)\n",
    "    background[:foreground_height,:foreground_width,:] = blended_portion\n",
    "    return background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open video file\n",
    "# video_file = \"project\"\n",
    "video_file = \"challenge\"\n",
    "# video_file = \"harder_challenge\"\n",
    "capture = cv.VideoCapture(\"./img/Udacity/\" + video_file + \"_video.mp4\")\n",
    "\n",
    "# Check if camera opened successfully\n",
    "if capture.isOpened() == False:\n",
    "    print(\"Error opening video stream or file\")\n",
    "\n",
    "# Start timer for fps counter\n",
    "start_timer = time.time() - 0.01\n",
    "frame_count = -1\n",
    "\n",
    "# Read every frame\n",
    "while capture.isOpened():\n",
    "    ret, frame = capture.read()\n",
    "\n",
    "    # Check if there is another frame\n",
    "    if frame is None:\n",
    "        break\n",
    "\n",
    "    orig = frame.copy()\n",
    "    orig = undistort_image(orig)\n",
    "\n",
    "    # Calculate Frame rate\n",
    "    frame_count += 1\n",
    "    ellapsed_time = time.time() - start_timer\n",
    "    frame_rate = frame_count / ellapsed_time\n",
    "\n",
    "    if ret == True:\n",
    "        start_time_measurement(\"frame\")\n",
    "\n",
    "        start_time_measurement(\"Undistort\")\n",
    "        frame = undistort_image_remap(frame)\n",
    "        end_time_measurement(\"Undistort\")\n",
    "\n",
    "        start_time_measurement(\"Warp\")\n",
    "        frame = warp_image_udacity(frame)\n",
    "        end_time_measurement(\"Warp\")\n",
    "\n",
    "        start_time_measurement(\"Brightness correction\")\n",
    "        frame, flag, brightness = correct_Brightness(frame)\n",
    "        end_time_measurement(\"Brightness correction\")\n",
    "\n",
    "        start_time_measurement(\"lane_detection\")\n",
    "        frame = lane_detection(frame, flag)\n",
    "        end_time_measurement(\"lane_detection\")\n",
    "\n",
    "        start_time_measurement(\"Sliding windows\")\n",
    "        midpoint, lefts, rights = sliding_windows(frame, minimum_whites=margin, show_windows=True)\n",
    "        end_time_measurement(\"Sliding windows\")\n",
    "\n",
    "        start_time_measurement(\"rewarp\")\n",
    "        frame = rewarp_image_udacity(frame)\n",
    "        end_time_measurement(\"rewarp\")\n",
    "\n",
    "        y_values = np.linspace(len(img), 0, nwindows+1).astype(int)\n",
    "\n",
    "        #--------------\n",
    "        frame = cv.cvtColor(frame, cv.COLOR_GRAY2BGR)\n",
    "\n",
    "        # start_time_measurement(\"Draw plane\")\n",
    "        # borderPoints = np.concatenate((lefts, np.flip(rights, axis=0)))\n",
    "        # cv.drawContours(frame, [borderPoints], -1, (255,0,0), -1)\n",
    "        # end_time_measurement(\"Draw plane\")\n",
    "        \n",
    "        out = combine_two_color_images(frame, orig)\n",
    "        #---------------\n",
    "\n",
    "        # Add frame rate to video\n",
    "        cv.putText(out, \"FPS: \" + str(round(frame_rate)), (0, 25),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2, cv.LINE_AA,)\n",
    "        cv.putText(out, \"Brightness: \" + str(round(brightness)), (0, 50),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2, cv.LINE_AA,)\n",
    "        cv.imshow(\"Frame\", out)\n",
    "\n",
    "\n",
    "        end_time_measurement(\"frame\")\n",
    "        # Close video with letter 'q'\n",
    "        if cv.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# When everything done, release the video capture object\n",
    "capture.release()\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "analyse_time_measurements()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3c5bf045d5047c0f00cfe2a5eb5fd13e5d63098e3da6354dfdacfff00d7c066"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
