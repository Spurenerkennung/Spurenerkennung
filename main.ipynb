{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "# video_file = \"project\"\n",
    "video_file = \"challenge\"\n",
    "\n",
    "DEBUG_MODE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_measurements = {}\n",
    "\n",
    "def start_time_measurement(eventName):\n",
    "    \"\"\"\n",
    "    Use this function to start a time measurement for a specific event.\n",
    "    A end_time_measurement() call with the same name must be called before the next start_time_measurement() call.\n",
    "    \"\"\"\n",
    "    add = False\n",
    "    if eventName not in time_measurements:\n",
    "        time_measurements[eventName] = {\n",
    "            \"name\": eventName,\n",
    "            \"start\": [],\n",
    "            \"end\": [],\n",
    "            \"count\": 0\n",
    "        }\n",
    "        add = True\n",
    "    elif len(time_measurements[eventName][\"start\"]) > len(time_measurements[eventName][\"end\"]):\n",
    "        print(f\"Time measure error: Event '{eventName}' not finished before reassignment!\")\n",
    "    else:\n",
    "       add = True\n",
    "    \n",
    "    #start measurement as late as possible\n",
    "    if add:\n",
    "        time_measurements[eventName][\"start\"].append(time.perf_counter_ns())\n",
    "\n",
    "def end_time_measurement(eventName):\n",
    "    \"\"\"\n",
    "    Use this function to end a time measurement for a specific event.\n",
    "    A time measurement with the same name must be started with start_time_measurement() before it can be ended.\n",
    "    \"\"\"\n",
    "    #end measurement as fast as possible\n",
    "    temp_time = time.perf_counter_ns()\n",
    "    if eventName not in time_measurements:\n",
    "        print(f\"Time measure error: Event '{eventName}' not defined!\")\n",
    "    elif len(time_measurements[eventName][\"end\"]) >= len(time_measurements[eventName][\"start\"]):\n",
    "        print(f\"Time measure error: Event '{eventName}' not started before reassignment!\")\n",
    "    else:\n",
    "        time_measurements[eventName][\"end\"].append(temp_time)\n",
    "        time_measurements[eventName][\"count\"] += 1\n",
    "    \n",
    "def analyse_time_measurements():\n",
    "    \"\"\"\n",
    "    Analyse time measurements and print them in a table.\n",
    "    \"\"\"\n",
    "    time_measurements_table = PrettyTable([\"Name\", \"Avg. [ms]\", \"Min. [ms]\", \"Max. [ms]\", \"Occurrences [compl.]\"])\n",
    "    time_measurements_table.align[\"Name\"] = \"l\"\n",
    "    time_measurements_table.align[\"Avg. [ms]\"] = \"r\"\n",
    "    time_measurements_table.align[\"Min. [ms]\"] = \"r\"\n",
    "    time_measurements_table.align[\"Max. [ms]\"] = \"r\"\n",
    "    time_measurements_table.align[\"Occurrences [compl.]\"] = \"r\"\n",
    "    for key, event in time_measurements.items():\n",
    "        timings = []\n",
    "        if len(event[\"start\"]) != len(event[\"end\"]):\n",
    "            print(f\"Time measure error: Event '{key}' has different amounts of values for start and end times!\")\n",
    "        else:\n",
    "            #exclude 0 values\n",
    "            for i in range(len(event[\"start\"])):\n",
    "                timing = (event[\"end\"][i] - event[\"start\"][i])\n",
    "                if timing >= 0:\n",
    "                    timing = timing / (1000 * 1000) #convert from ns to ms\n",
    "                    timings.append(timing)\n",
    "\n",
    "            event[\"min\"] = min(timings) \n",
    "            event[\"max\"] = max(timings)\n",
    "            event[\"avg\"] = sum(timings) / len(event[\"start\"])\n",
    "\n",
    "            time_measurements_table.add_row([key, '{0:.2f}'.format(event[\"avg\"]), '{0:.2f}'.format(event[\"min\"]), '{0:.2f}'.format(event[\"max\"]), event[\"count\"]])\n",
    "    print(time_measurements_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kamerakalibrierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of chessboard, minimum error with (7, 6), but there were severe artifacts at the borders (see error calculation at the end)\n",
    "chessboard_x, chessboard_y = 9, 6\n",
    "\n",
    "# termination criteria\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((chessboard_y * chessboard_x, 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:chessboard_x, 0:chessboard_y].T.reshape(-1, 2)\n",
    "# Arrays to store object points and image points from all the images.\n",
    "object_points = []  # 3d point in real world space\n",
    "image_points = []  # 2d points in image plane.\n",
    "\n",
    "# use all calibration images\n",
    "images = glob.glob(\"./img/Udacity/calib/*.jpg\")\n",
    "for i, fname in enumerate(images):\n",
    "    img = cv.imread(fname)\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chess board corners\n",
    "    ret, corners = cv.findChessboardCorners(gray, (chessboard_x, chessboard_y), None)\n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if ret == True:\n",
    "        object_points.append(objp)\n",
    "        corners2 = cv.cornerSubPix(\n",
    "            gray, corners, (11, 11), (-1, -1), criteria\n",
    "        )  # improve accuracy of corners\n",
    "        image_points.append(corners)\n",
    "\n",
    "ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(\n",
    "    object_points, image_points, gray.shape[::-1], None, None\n",
    ")\n",
    "\n",
    "image_height, image_width = img.shape[:2]\n",
    "newcameramtx, roi = cv.getOptimalNewCameraMatrix(mtx, dist, (image_width, image_height), 1, (image_width, image_height))\n",
    "\n",
    "\n",
    "# ------- define functions for image processing -------\n",
    "def undistort_image(img):\n",
    "    img_undistorted = cv.undistort(img, mtx, dist, None, newcameramtx)\n",
    "    # crop the image\n",
    "    x, y, w, h = roi\n",
    "    return img_undistorted[y : y + h, x : x + w]\n",
    "\n",
    "# ~50% faster than undistort_image()\n",
    "def undistort_image_remap(img):\n",
    "    h, w = img.shape[:2]\n",
    "    \n",
    "    map_x, map_y = cv.initUndistortRectifyMap(mtx, dist, None, newcameramtx, (w, h), 5)\n",
    "    dst = cv.remap(img, map_x, map_y, cv.INTER_LINEAR)\n",
    "    # crop the image\n",
    "    x, y, w, h = roi\n",
    "    return dst[y : y + h, x : x + w]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perspektivtransformation\n",
    "\n",
    "Mögliche Performance-verbesserung:\n",
    "\n",
    "- Bild nach warp verkleinern, da ein großteil des Bildes aus wenigen Pixeln entsteht -> nicht gemacht weil probleme beim rückwarpen\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# udacity images\n",
    "if video_file == \"harder_challenge\":\n",
    "    src_udacity = np.float32([[20, 628], [191+100, 404], [1200, 628], [1021-100, 404]])\n",
    "    dst_udacity = np.float32([[150, 720], [150, 10], [1000, 720], [1000, 10]])\n",
    "else:\n",
    "    src_udacity = np.float32([[191, 628], [531, 404], [1021, 628], [681, 404]])\n",
    "    dst_udacity = np.float32([[150, 720], [150, 10], [1000, 720], [1000, 10]])\n",
    "\n",
    "M_warp = cv.getPerspectiveTransform(src_udacity, dst_udacity)\n",
    "M_rewarp = cv.getPerspectiveTransform(dst_udacity, src_udacity)\n",
    "\n",
    "\n",
    "def warp_image_udacity(img):\n",
    "    image = cv.warpPerspective(img, M_warp, (img.shape[1], img.shape[0]))\n",
    "    if DEBUG_MODE:\n",
    "        #Draw a red circle with zero radius and -1 for filled circle\n",
    "        for src in src_udacity:\n",
    "            image2 = cv.circle(img, np.int32(src), radius=0, color=(0, 0, 255), thickness=5)\n",
    "        cv.imshow(\"Transformed\", image2)\n",
    "    return image\n",
    "\n",
    "# todo deprecated in main branch\n",
    "def rewarp_image_udacity(img):\n",
    "    img = cv.warpPerspective(img, M_rewarp, (img.shape[1], img.shape[0]), cv.WARP_INVERSE_MAP)\n",
    "    return img\n",
    "\n",
    "def rewarp_points_udacity(points):\n",
    "    \"\"\"\n",
    "    Rewarp points from warped image coordinates to original image coordinates.\n",
    "    \n",
    "    Args:\n",
    "        points (np.array): float32 array \n",
    "        \n",
    "    @return: points in original image coordinates\n",
    "    \"\"\"\n",
    "    return cv.perspectiveTransform(points, M_rewarp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sliding Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_windows = 50\n",
    "margin = 50\n",
    "def sliding_windows(frame, window_width=200, minimum_whites=30):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        frame (image): input frame with masked lane lines\n",
    "        window_width (int, optional): width of windows. Defaults to 200.\n",
    "        minimum_whites (int, optional): todo. Defaults to 30.\n",
    "\n",
    "    Returns:\n",
    "        lefts, rights (np.array): returns left and right points as 2d array of sliding window centers\n",
    "    \"\"\"\n",
    "    # Histogram for image\n",
    "    hist = np.sum(frame[frame.shape[0]//2:, :], axis=0)\n",
    "        \n",
    "    # Take peaks from left and right side of histogram for starting points and add half margin\n",
    "    mid_point_x = np.int32(hist.shape[0] // 2)\n",
    "    left_x_start = np.argmax(hist[:mid_point_x]) - window_width // 2\n",
    "    right_x_start = np.argmax(hist[mid_point_x:]) + mid_point_x + window_width // 2\n",
    "    # Window height based on number of windows\n",
    "    window_height = np.int32(frame.shape[0] // number_windows)\n",
    "    \n",
    "    # Calc points that are not zero in images\n",
    "    nonzero = frame.nonzero()\n",
    "    nonzero_y = np.array(nonzero[0])\n",
    "    nonzero_x = np.array(nonzero[1])\n",
    "    \n",
    "    # Initialize current positions for windows\n",
    "    left_x_current = left_x_start\n",
    "    right_x_current = right_x_start\n",
    "\n",
    "    # Initialize values to be returned -> centers of windows\n",
    "    lefts_good = np.empty((0,2), dtype=np.int32)\n",
    "    rights_good = np.empty((0,2), dtype=np.int32)\n",
    "\n",
    "    # Go through every window\n",
    "    for window in range(number_windows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = frame.shape[0] - (window + 1) * window_height\n",
    "        win_y_high = frame.shape[0] - window*window_height\n",
    "        y_mid = (win_y_low + win_y_high) // 2\n",
    "        \n",
    "        # Calculate boundaries of the window\n",
    "        win_xleft_low = left_x_current - window_width  \n",
    "        win_xleft_high = left_x_current + window_width  \n",
    "        win_xright_low =  right_x_current - window_width \n",
    "        win_xright_high = right_x_current + window_width  \n",
    "        \n",
    "        # Identify the pixels that are not zero within window\n",
    "        left_inds = ((nonzero_y >= win_y_low ) & (nonzero_y < win_y_high) & (nonzero_x >= win_xleft_low) & (nonzero_x < win_xleft_high)).nonzero()[0]\n",
    "        right_inds = ((nonzero_y >= win_y_low ) & (nonzero_y < win_y_high) & (nonzero_x >= win_xright_low) & (nonzero_x < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # If more than minimum pixels are found -> recenter next window\n",
    "        if len(left_inds) > minimum_whites:\n",
    "            left_x_current = np.int32(np.mean(nonzero_x[left_inds]))\n",
    "            lefts_good = np.concatenate((lefts_good, [[left_x_current, y_mid]]))\n",
    "            if DEBUG_MODE:\n",
    "                cv.rectangle(frame, (left_x_current - margin, win_y_low),(left_x_current + margin, win_y_high),(255, 255, 255), 2)\n",
    "        if len(right_inds) > minimum_whites:\n",
    "            right_x_current = np.int32(np.mean(nonzero_x[right_inds]))\n",
    "            rights_good = np.concatenate((rights_good, [[right_x_current, y_mid]]))\n",
    "            if DEBUG_MODE:\n",
    "                cv.rectangle(frame, (right_x_current - margin, win_y_low),(right_x_current + margin, win_y_high),(255, 255, 255), 2)\n",
    "\n",
    "    return lefts_good, rights_good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomes\n",
    "calculation from center points of the sliding windows\n",
    "\n",
    "and drawing points on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  calculate polynomial from rewarped points\n",
    "def calculate_polynomial_points(lefts, rights):\n",
    "    \"\"\"\n",
    "    calculate polynomial from rewarped points and then return list of points on the polynomial\n",
    "    @return: array of points for left and right polynomial\n",
    "    \"\"\"\n",
    "    # check if there are enough points\n",
    "    if len(lefts) < 2 or len(rights) < 2:\n",
    "        return None, None\n",
    "    \n",
    "    # calculate polynomial from rewarped points\n",
    "    left_polynom_values = np.polyfit(lefts[:,1], lefts[:,0], 2)\n",
    "    right_polynom_values = np.polyfit(rights[:,1], rights[:,0], 2)\n",
    "\n",
    "    # 750 as x length of polynom\n",
    "    x_axis = np.linspace(0, 750, 750) \n",
    "\n",
    "    # calculate y values for left and right line\n",
    "    left_line_y = left_polynom_values[0]*x_axis**2 + left_polynom_values[1]*x_axis + left_polynom_values[2]\n",
    "    right_line_y = right_polynom_values[0]*x_axis**2 + right_polynom_values[1]*x_axis + right_polynom_values[2]\n",
    "\n",
    "    # array of points for left and right line from x and y values\n",
    "    left_pts = np.array([np.transpose(np.vstack([left_line_y, x_axis]))])\n",
    "    right_pts = np.array([np.transpose(np.vstack([right_line_y, x_axis]))])\n",
    "\n",
    "    return left_pts, right_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawRecOnFrame(frame, left_pts, right_pts):\n",
    "    \"\"\"\n",
    "    Rewarp points to original image coordinates and draw rectangle on frame.\n",
    "    \n",
    "    input: array of points from left and right lane marking in warped image\n",
    "    e.g.:\n",
    "      [[ 281   39]\n",
    "      [ 971  163]\n",
    "      [ 958  101]]\n",
    "    \"\"\"\n",
    "    if len(left_pts) + len(right_pts) > 3:\n",
    "      borderPoints = np.concatenate((np.flip(left_pts, axis=0), right_pts))\n",
    "      borderPointsRewarped = rewarp_points_udacity(np.array([borderPoints], dtype=np.float32))\n",
    "      borderPointsRewarpedInt = borderPointsRewarped.astype(int)\n",
    "      # draw final polygon in frame\n",
    "      cv.drawContours(frame, borderPointsRewarpedInt, -1, (0,255,0), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo deprecated\n",
    "def applyMasks(frame):\n",
    "    \"\"\"\n",
    "    Apply masks to frame and return frame with only lane marking.\n",
    "    \"\"\"\n",
    "    ## convert to hsv\n",
    "    hls_frame = cv.cvtColor(frame, cv.COLOR_BGR2HLS)\n",
    "\n",
    "    ## mask for white\n",
    "    white_mask = cv.inRange(hls_frame, (0, 200, 0), (255, 255,255))\n",
    "\n",
    "    ## mask for yellow\n",
    "    # yellow_mask = cv.inRange(hls_frame, (20,90,200), (26, 255, 255))\n",
    "    yellow_mask = cv.inRange(hls_frame, (10,0,100), (40, 255, 255))\n",
    "\n",
    "    ## final mask and masked\n",
    "    mask = cv.bitwise_or(white_mask, yellow_mask)\n",
    "    frame = cv.bitwise_and(frame,frame, mask=mask)\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lane_detection(frame, white_lower, white_upper, yellow_lower, yellow_upper):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        frame (_type_): _description_\n",
    "        white_lower (_type_): _description_\n",
    "        white_upper (_type_): _description_\n",
    "        yellow_lower (_type_): _description_\n",
    "        yellow_upper (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    frame = cv.GaussianBlur(frame, (5, 5), 0)\n",
    "    frame_hls = cv.cvtColor(frame, cv.COLOR_BGR2HLS)\n",
    "\n",
    "    white_mask = cv.inRange(frame_hls, white_lower, white_upper)\n",
    "    white_mask[:, 0:200] = 0\n",
    "\n",
    "    frame_lab = cv.cvtColor(frame, cv.COLOR_BGR2LAB)\n",
    "    yellow_mask = cv.inRange(frame_lab, yellow_lower, yellow_upper)\n",
    "    yellow_mask[:, 1000:] = 0\n",
    "    combined_mask = cv.bitwise_or(white_mask, yellow_mask)\n",
    "    \n",
    "    if DEBUG_MODE: # needs frame at this point\n",
    "        frame_luv = cv.cvtColor(frame, cv.COLOR_BGR2LUV)\n",
    "        greenImg = np.zeros(frame.shape, frame.dtype)\n",
    "        redImg = np.zeros(frame.shape, frame.dtype)\n",
    "\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_RECT, (13, 13))\n",
    "    lanes_yellow = cv.morphologyEx(frame_lab[:, :, 2], cv.MORPH_TOPHAT, kernel)\n",
    "\n",
    "    ret, lanes_yellow = cv.threshold(lanes_yellow, thresh=2, maxval=255, type=cv.THRESH_BINARY)\n",
    "    lanes_yellow = cv.morphologyEx(lanes_yellow, cv.MORPH_OPEN, np.array([[0,1,0],[1,1,1],[0,1,0]], 'uint8'), iterations=4)\n",
    "\n",
    "    combined_mask = cv.bitwise_or(combined_mask, lanes_yellow)\n",
    "\n",
    "    combined_mask = cv.morphologyEx(combined_mask, cv.MORPH_OPEN, np.array([[0,1,0],[1,1,1],[0,1,0]], 'uint8'), iterations=2)\n",
    "    frame = cv.bitwise_and(frame, frame, mask=combined_mask)\n",
    "    frame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    \n",
    "    if DEBUG_MODE: # show multiple debug images\n",
    "        cv.imshow(\"LUV\", frame_luv[:,:,2])\n",
    "        \n",
    "        redImg[:,:] = (0, 0, 255)\n",
    "        redMask = cv.bitwise_and(redImg, redImg, mask=yellow_mask)\n",
    "\n",
    "        greenImg[:,:] = (0, 255, 0)\n",
    "        greenMask = cv.bitwise_and(greenImg, greenImg, mask=white_mask)\n",
    "        masks = redMask + greenMask\n",
    "        cv.imshow(\"Masks\", masks)\n",
    "        \n",
    "        lanes = cv.morphologyEx(frame_hls[:, :, 1], cv.MORPH_BLACKHAT, kernel)\n",
    "        ret, lanes = cv.threshold(lanes, thresh=10, maxval=255, type=cv.THRESH_BINARY)\n",
    "        cv.imshow(\"BLACK_HAT_LANES\", lanes)\n",
    "\n",
    "        ret, canny = cv.threshold(frame_lab[:,:,2], thresh=140, maxval=255, type=cv.THRESH_BINARY)\n",
    "        half = canny.shape[1]//2\n",
    "        new_canny = canny[100:, :half] \n",
    "        cv.imshow(\"LAB_Canny\", new_canny)\n",
    "    \n",
    "        cv.imshow(\"LAB\", frame_lab[:,:,2])\n",
    "        cv.imshow(\"LAB_combined\", cv.bitwise_and(canny, lanes_yellow))\n",
    "        cv.imshow(\"HLS\", frame_hls)\n",
    "        \n",
    "        cv.imshow(\"TOP_HAT_LANES_YELLOW\", lanes_yellow)\n",
    "        cv.imshow(\"Final\", combined_mask)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_Brightness(frame):\n",
    "    frame_hsv = cv.cvtColor(frame, cv.COLOR_BGR2HSV)\n",
    "    brightness = frame_hsv[...,2].mean()\n",
    "    brightness_upper_limit = 150\n",
    "    brightness_lower_limit = 85\n",
    "    if brightness > brightness_upper_limit:\n",
    "        h, s, v = cv.split(frame_hsv)\n",
    "        \n",
    "        lim = round(0 + brightness - brightness_upper_limit)\n",
    "        v[v < lim] = 0\n",
    "        v[v >= lim] -= lim\n",
    "\n",
    "        final_hsv = cv.merge((h, s, v))\n",
    "        frame = cv.cvtColor(final_hsv, cv.COLOR_HSV2BGR)\n",
    "    \n",
    "    elif brightness < brightness_lower_limit:\n",
    "        h, s, v = cv.split(frame_hsv)\n",
    "        \n",
    "        lim = round(255 + brightness_lower_limit - brightness)\n",
    "        v[v > lim] = 255\n",
    "        v[v <= lim] += lim\n",
    "\n",
    "        final_hsv = cv.merge((h, s, v))\n",
    "        frame = cv.cvtColor(final_hsv, cv.COLOR_HSV2BGR)\n",
    "\n",
    "    frame_hsv = cv.cvtColor(frame, cv.COLOR_BGR2HSV)\n",
    "    brightness = frame_hsv[...,2].mean()\n",
    "\n",
    "    return frame, brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_change(value):\n",
    "    global next\n",
    "    next = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eddi\\AppData\\Local\\Temp\\ipykernel_21224\\2470665765.py:176: RankWarning: Polyfit may be poorly conditioned\n",
      "  left_pts, right_pts = calculate_polynomial_points(lefts, rights)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+-----------+-----------+-----------+----------------------+\n",
      "| Name                   | Avg. [ms] | Min. [ms] | Max. [ms] | Occurrences [compl.] |\n",
      "+------------------------+-----------+-----------+-----------+----------------------+\n",
      "| frame                  |     52.34 |     41.99 |    307.51 |                   34 |\n",
      "| Preprocessing          |      5.25 |      4.48 |     21.01 |                   34 |\n",
      "| masking                |     33.61 |     26.92 |    181.13 |                   34 |\n",
      "| sliding windows        |      6.50 |      5.19 |     20.58 |                   34 |\n",
      "| polynomial calculation |      0.25 |      0.23 |      0.58 |                   34 |\n",
      "| draw plane             |      0.19 |      0.17 |      0.22 |                   34 |\n",
      "+------------------------+-----------+-----------+-----------+----------------------+\n"
     ]
    }
   ],
   "source": [
    "# Open video file\n",
    "capture = cv.VideoCapture(\"./img/Udacity/\" + video_file + \"_video.mp4\")\n",
    "\n",
    "# Check if camera opened successfully\n",
    "if capture.isOpened() == False:\n",
    "    print(\"Error opening video stream or file\")\n",
    "\n",
    "# Start timer for fps counter\n",
    "start_timer = time.time() - 0.01\n",
    "frame_count = -1\n",
    "\n",
    "frames = []\n",
    "next = True\n",
    "\n",
    "while capture.isOpened():\n",
    "    ret, frame = capture.read()\n",
    "\n",
    "    # Check if there is another frame\n",
    "    if frame is None:\n",
    "        break\n",
    "\n",
    "    frames.append(frame)\n",
    "\n",
    "position = 0\n",
    "window = cv.namedWindow(\"Options\", cv.WINDOW_NORMAL)\n",
    "cv.createTrackbar('Frame', 'Options', 0, len(frames), on_change)\n",
    "\n",
    "cv.createTrackbar('white_lower_1', 'Options', 0, 255, on_change)\n",
    "cv.createTrackbar('white_lower_2', 'Options', 0, 255, on_change)\n",
    "cv.createTrackbar('white_lower_3', 'Options', 0, 255, on_change)\n",
    "\n",
    "cv.createTrackbar('white_upper_1', 'Options', 0, 255, on_change)\n",
    "cv.createTrackbar('white_upper_2', 'Options', 0, 255, on_change)\n",
    "cv.createTrackbar('white_upper_3', 'Options', 0, 255, on_change)\n",
    "\n",
    "cv.createTrackbar('yellow_lower_1', 'Options', 0, 255, on_change)\n",
    "cv.createTrackbar('yellow_lower_2', 'Options', 0, 255, on_change)\n",
    "cv.createTrackbar('yellow_lower_3', 'Options', 0, 255, on_change)\n",
    "\n",
    "cv.createTrackbar('yellow_upper_1', 'Options', 0, 255, on_change)\n",
    "cv.createTrackbar('yellow_upper_2', 'Options', 0, 255, on_change)\n",
    "cv.createTrackbar('yellow_upper_3', 'Options', 0, 255, on_change)\n",
    "\n",
    "yellow_lower = np.array([150, 100, 140])\n",
    "yellow_upper = np.array([255, 140, 200])\n",
    "\n",
    "white_lower = np.array([0, 180, 0])\n",
    "white_upper = np.array([254, 254, 254])\n",
    "\n",
    "cv.setTrackbarPos('white_lower_1', 'Options', white_lower[0])\n",
    "cv.setTrackbarPos('white_lower_2', 'Options', white_lower[1])\n",
    "cv.setTrackbarPos('white_lower_3', 'Options', white_lower[2])\n",
    "\n",
    "cv.setTrackbarPos('white_upper_1', 'Options', white_upper[0]) \n",
    "cv.setTrackbarPos('white_upper_2', 'Options', white_upper[1])\n",
    "cv.setTrackbarPos('white_upper_3', 'Options', white_upper[2])\n",
    "\n",
    "cv.setTrackbarPos('yellow_lower_1', 'Options', yellow_lower[0])\n",
    "cv.setTrackbarPos('yellow_lower_2', 'Options', yellow_lower[1])\n",
    "cv.setTrackbarPos('yellow_lower_3', 'Options', yellow_lower[2])\n",
    "\n",
    "cv.setTrackbarPos('yellow_upper_1', 'Options', yellow_upper[0])\n",
    "cv.setTrackbarPos('yellow_upper_2', 'Options', yellow_upper[1])\n",
    "cv.setTrackbarPos('yellow_upper_3', 'Options', yellow_upper[2])\n",
    "\n",
    "# Read every frame\n",
    "while position < len(frames):\n",
    "\n",
    "    frame = frames[position]\n",
    "\n",
    "    # Check if there is another frame\n",
    "    if frame is None:\n",
    "        break\n",
    "\n",
    "    # Calculate Frame rate\n",
    "    if next:\n",
    "\n",
    "        white_lower[0] = cv.getTrackbarPos('white_lower_1', 'Options')\n",
    "        white_lower[1] = cv.getTrackbarPos('white_lower_2', 'Options')\n",
    "        white_lower[2] = cv.getTrackbarPos('white_lower_3', 'Options')\n",
    "\n",
    "        white_upper[0] = cv.getTrackbarPos('white_upper_1', 'Options')\n",
    "        white_upper[1] = cv.getTrackbarPos('white_upper_2', 'Options')\n",
    "        white_upper[2] = cv.getTrackbarPos('white_upper_3', 'Options')\n",
    "\n",
    "        yellow_lower[0] = cv.getTrackbarPos('yellow_lower_1', 'Options')\n",
    "        yellow_lower[1] = cv.getTrackbarPos('yellow_lower_2', 'Options')\n",
    "        yellow_lower[2] = cv.getTrackbarPos('yellow_lower_3', 'Options')\n",
    "\n",
    "        yellow_upper[0] = cv.getTrackbarPos('yellow_upper_1', 'Options')\n",
    "        yellow_upper[1] = cv.getTrackbarPos('yellow_upper_2', 'Options')\n",
    "        yellow_upper[2] = cv.getTrackbarPos('yellow_upper_3', 'Options')\n",
    "\n",
    "\n",
    "        frame_count += 1\n",
    "        elapsed_time = time.time() - start_timer\n",
    "        frame_rate = frame_count / elapsed_time\n",
    "        \n",
    "        start_time_measurement(\"frame\")\n",
    "        \n",
    "        # ----------- Preprocessing ---------------\n",
    "        start_time_measurement(\"Preprocessing\")\n",
    "        frame = undistort_image_remap(frame)\n",
    "        frame_undistorted = frame.copy()\n",
    "        frame = warp_image_udacity(frame)\n",
    "        end_time_measurement(\"Preprocessing\")\n",
    "\n",
    "\n",
    "        img = frame\n",
    "        height = img.shape[0]\n",
    "        width = img.shape[1]\n",
    "\n",
    "        width_cutoff = width // 2\n",
    "\n",
    "        left1 = img[:, :width_cutoff]\n",
    "        right1 = img[:, width_cutoff:]\n",
    "\n",
    "        img = cv.rotate(left1, cv.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "        height = img.shape[0]\n",
    "        width = img.shape[1]\n",
    "        width_cutoff = width // 2\n",
    "\n",
    "        l1 = img[:, :width_cutoff]\n",
    "        l2 = img[:, width_cutoff:]\n",
    "        l1 = cv.rotate(l1, cv.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        l2 = cv.rotate(l2, cv.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "        img = cv.rotate(right1, cv.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "        height = img.shape[0]\n",
    "        width = img.shape[1]\n",
    "        width_cutoff = width // 2\n",
    "\n",
    "        r1 = img[:, :width_cutoff]\n",
    "        r2 = img[:, width_cutoff:]\n",
    "        r1 = cv.rotate(r1, cv.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        r2 = cv.rotate(r2, cv.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "        cv.imshow(\"one_horisont_1.jpg\", l1)\n",
    "        cv.imshow(\"one_horisont_2.jpg\", l2)\n",
    "        cv.imshow(\"second_vhorisont_1.jpg\", r1)\n",
    "        cv.imshow(\"second_horisont_2.jpg\", r2)\n",
    "        \n",
    "        # ---------  Masking ---------------------\n",
    "        start_time_measurement(\"masking\")\n",
    "        # frame = applyMasks(frame)\n",
    "        l1, brightness = correct_Brightness(l1)\n",
    "        grayscale_frame_l1 = lane_detection(l1, white_lower, white_upper, yellow_lower, yellow_upper)\n",
    "\n",
    "        l2, brightness = correct_Brightness(l2)\n",
    "        grayscale_frame_l2 = lane_detection(l2, white_lower, white_upper, yellow_lower, yellow_upper)\n",
    "\n",
    "        r1, brightness = correct_Brightness(r1)\n",
    "        grayscale_frame_r1 = lane_detection(r1, white_lower, white_upper, yellow_lower, yellow_upper)\n",
    "\n",
    "        r2, brightness = correct_Brightness(r2)\n",
    "        grayscale_frame_r2 = lane_detection(r2, white_lower, white_upper, yellow_lower, yellow_upper)\n",
    "        end_time_measurement(\"masking\")\n",
    "\n",
    "\n",
    "        numpy_vertical_l = np.vstack((grayscale_frame_l2, grayscale_frame_l1))\n",
    "        numpy_vertical_r = np.vstack((grayscale_frame_r2, grayscale_frame_r1))\n",
    "        grayscale_frame = np.hstack((numpy_vertical_l, numpy_vertical_r))\n",
    "\n",
    "        cv.imshow(\"Test\", grayscale_frame)\n",
    "        #---------- Sliding Windows ----------\n",
    "        start_time_measurement(\"sliding windows\")\n",
    "        # Convert to grayscale for sliding windows\n",
    "        lefts, rights = sliding_windows(grayscale_frame, minimum_whites=margin)\n",
    "        end_time_measurement(\"sliding windows\")\n",
    "\n",
    "\n",
    "        #---------- Calculate polynomial ----------\n",
    "        start_time_measurement(\"polynomial calculation\")\n",
    "        left_pts, right_pts = calculate_polynomial_points(lefts, rights)\n",
    "        end_time_measurement(\"polynomial calculation\")\n",
    "\n",
    "        # -------- draw plane from all sliding windows ------------\n",
    "        start_time_measurement(\"draw plane\")\n",
    "        if left_pts is not None and right_pts is not None:\n",
    "            drawRecOnFrame(frame_undistorted, left_pts[0], right_pts[0])\n",
    "        end_time_measurement(\"draw plane\")\n",
    "\n",
    "        # -------- Add frame rate to video ------------\n",
    "        cv.putText(frame_undistorted, \"FPS: \" + str(round(frame_rate)), (0, 25),\n",
    "                    cv.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2, cv.LINE_AA,)\n",
    "        cv.putText(frame_undistorted, \"Frame: \" + str(frame_count), (0, 50), cv.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2, cv.LINE_AA,)\n",
    "        cv.putText(frame_undistorted, \"Brightness: \" + str(np.round(brightness)), (0, 75), cv.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2, cv.LINE_AA,)\n",
    "        cv.imshow(\"Frame\", frame_undistorted)\n",
    "\n",
    "        end_time_measurement(\"frame\")\n",
    "        next = False\n",
    "        \n",
    "    pressedKey = cv.waitKey(1) & 0xFF\n",
    "    if pressedKey == ord('q'):\n",
    "        break\n",
    "    elif pressedKey == ord('w'):\n",
    "        position += 1\n",
    "        cv.setTrackbarPos('Frame', 'Options', position)\n",
    "        next = True\n",
    "    elif pressedKey == ord('s') and position > 0:\n",
    "        position -= 1\n",
    "        cv.setTrackbarPos('Frame', 'Options', position)\n",
    "        next = True\n",
    "    elif cv.getTrackbarPos('Frame', 'Options') != position:\n",
    "        position = cv.getTrackbarPos('Frame', 'Options')\n",
    "        next = True\n",
    "\n",
    "# When everything done, release the video capture object\n",
    "capture.release()\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "# create time measurement analysis and print out results\n",
    "analyse_time_measurements()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
