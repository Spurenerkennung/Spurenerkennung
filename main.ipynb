{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_measurements = {}\n",
    "\n",
    "def start_time_measurement(eventName):\n",
    "    add = False\n",
    "    if eventName not in time_measurements:\n",
    "        time_measurements[eventName] = {\n",
    "            \"name\": eventName,\n",
    "            \"start\": [],\n",
    "            \"end\": [],\n",
    "            \"count\": 0\n",
    "        }\n",
    "        add = True\n",
    "    elif len(time_measurements[eventName][\"start\"]) > len(time_measurements[eventName][\"end\"]):\n",
    "        print(f\"Time measure error: Event '{eventName}' not finished before reassignment!\")\n",
    "    else:\n",
    "       add = True\n",
    "    \n",
    "    #start measurement as late as possible\n",
    "    if add:\n",
    "        time_measurements[eventName][\"start\"].append(time.perf_counter_ns())\n",
    "\n",
    "def end_time_measurement(eventName):\n",
    "    #end measurement as fast as possible\n",
    "    temp_time = time.perf_counter_ns()\n",
    "    if eventName not in time_measurements:\n",
    "        print(f\"Time measure error: Event '{eventName}' not defined!\")\n",
    "    elif len(time_measurements[eventName][\"end\"]) >= len(time_measurements[eventName][\"start\"]):\n",
    "        print(f\"Time measure error: Event '{eventName}' not started before reassignment!\")\n",
    "    else:\n",
    "        time_measurements[eventName][\"end\"].append(temp_time)\n",
    "        time_measurements[eventName][\"count\"] += 1\n",
    "\n",
    "def analyse_time_measurements():\n",
    "    time_measurements_table = PrettyTable([\"Name\", \"Avg. [ms]\", \"Min. [ms]\", \"Max. [ms]\", \"Occurrences [compl.]\"])\n",
    "    time_measurements_table.align[\"Name\"] = \"l\"\n",
    "    time_measurements_table.align[\"Avg. [ms]\"] = \"r\"\n",
    "    time_measurements_table.align[\"Min. [ms]\"] = \"r\"\n",
    "    time_measurements_table.align[\"Max. [ms]\"] = \"r\"\n",
    "    time_measurements_table.align[\"Occurrences [compl.]\"] = \"r\"\n",
    "    for key, event in time_measurements.items():\n",
    "        timings = []\n",
    "        if len(event[\"start\"]) != len(event[\"end\"]):\n",
    "            print(f\"Time measure error: Event '{key}' has different amounts of values for start and end times!\")\n",
    "        else:\n",
    "            #exclude 0 values\n",
    "            for i in range(len(event[\"start\"])):\n",
    "                timing = (event[\"end\"][i] - event[\"start\"][i])\n",
    "                if timing >= 0:\n",
    "                    timing = timing / (1000 * 1000) #convert from ns to ms\n",
    "                    timings.append(timing)\n",
    "\n",
    "            event[\"min\"] = min(timings) \n",
    "            event[\"max\"] = max(timings)\n",
    "            event[\"avg\"] = sum(timings) / len(event[\"start\"])\n",
    "\n",
    "            time_measurements_table.add_row([key, '{0:.2f}'.format(event[\"avg\"]), '{0:.2f}'.format(event[\"min\"]), '{0:.2f}'.format(event[\"max\"]), event[\"count\"]])\n",
    "    print(time_measurements_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kamerakalibrierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of chessboard, minimum error with (7, 6), but there were severe artefacts at the borders (see error calculation at the end)\n",
    "x, y = 9, 6\n",
    "\n",
    "# termination criteria\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((y * x, 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:x, 0:y].T.reshape(-1, 2)\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = []  # 3d point in real world space\n",
    "imgpoints = []  # 2d points in image plane.\n",
    "\n",
    "\n",
    "images = glob.glob(\"./img/Udacity/calib/*.jpg\")\n",
    "for i, fname in enumerate(images):\n",
    "    img = cv.imread(fname)\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chess board corners\n",
    "    ret, corners = cv.findChessboardCorners(gray, (x, y), None)\n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        corners2 = cv.cornerSubPix(\n",
    "            gray, corners, (11, 11), (-1, -1), criteria\n",
    "        )  # improve accuracy of corners\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(\n",
    "    objpoints, imgpoints, gray.shape[::-1], None, None\n",
    ")\n",
    "\n",
    "h, w = img.shape[:2]\n",
    "newcameramtx, roi = cv.getOptimalNewCameraMatrix(mtx, dist, (w, h), 1, (w, h))\n",
    "\n",
    "\n",
    "def undistort_image(img):\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    img_undist = cv.undistort(img, mtx, dist, None, newcameramtx)\n",
    "    # crop the image\n",
    "    x, y, w, h = roi\n",
    "    return img_undist[y : y + h, x : x + w]\n",
    "\n",
    "\n",
    "# ~50% faster than undistort_image()\n",
    "def undistort_image_remap(img):\n",
    "    h, w = img.shape[:2]\n",
    "    mapx, mapy = cv.initUndistortRectifyMap(mtx, dist, None, newcameramtx, (w, h), 5)\n",
    "    dst = cv.remap(img, mapx, mapy, cv.INTER_LINEAR)\n",
    "    # crop the image\n",
    "    x, y, w, h = roi\n",
    "    return dst[y : y + h, x : x + w]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perspektivtransformation\n",
    "\n",
    "Mögliche Performance-verbesserung:\n",
    "\n",
    "- Bild nach warp verkleinern, da ein großteil des Bildes aus wenigen Pixeln entsteht ->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# udacity images\n",
    "src_udacity = np.float32([[191, 628], [531, 404], [1021, 628], [681, 404]])\n",
    "dst_udacity = np.float32([[150, 720], [150, 10], [1000, 720], [1000, 10]])\n",
    "M_warp = cv.getPerspectiveTransform(src_udacity, dst_udacity)\n",
    "M_rewarp = cv.getPerspectiveTransform(dst_udacity, src_udacity)\n",
    "\n",
    "\n",
    "def warp_image_udacity(img):\n",
    "    img = cv.warpPerspective(img, M_warp, (img.shape[1], img.shape[0]))\n",
    "    # image = cv.resize(\n",
    "    #     image, (int(img.shape[1] / 2), int(img.shape[0] / 2))\n",
    "    # )  # resize to half size\n",
    "    return img\n",
    "\n",
    "def rewarp_image_udacity(img):\n",
    "    # image = cv.resize(\n",
    "    #     img, (int(img.shape[1] * 2), int(img.shape[0] * 2))\n",
    "    # ) \n",
    "    img = cv.warpPerspective(img, M_rewarp, (img.shape[1], img.shape[0]))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sliding Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwindows = 10\n",
    "margin = 50\n",
    "def sliding_windows(frame, window_width=200, minimum_whites=30, show_windows=False):\n",
    "    # Histogram for image\n",
    "    hist = np.sum(frame[frame.shape[0]//2:, :], axis=0)\n",
    "        \n",
    "    # Take peaks from left and right side of histogramm for starting points and add half margin\n",
    "    mid = np.int(hist.shape[0] // 2)\n",
    "    leftx_start = np.argmax(hist[:mid]) - window_width // 2\n",
    "    rightx_start = np.argmax(hist[mid:]) + mid + window_width // 2\n",
    "    # Window height based on number of windows\n",
    "    window_height = np.int(frame.shape[0] // nwindows)\n",
    "    \n",
    "    # Calc points that are not zero in images\n",
    "    nonzero = frame.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    # Initialize current positions for windows\n",
    "    leftx_current = leftx_start\n",
    "    rightx_current = rightx_start\n",
    "\n",
    "    # Initialize values to be returned -> centers of windows\n",
    "    lefts_good = np.empty(shape=(1,1), dtype=int)\n",
    "    rights_good = np.empty(shape=(1,1), dtype=int)\n",
    "\n",
    "    # Go through every window\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = frame.shape[0] - (window + 1) * window_height\n",
    "        win_y_high = frame.shape[0] - window*window_height\n",
    "        \n",
    "        # Calculate boundaries of the window\n",
    "        win_xleft_low = leftx_current - window_width  \n",
    "        win_xleft_high = leftx_current + window_width  \n",
    "        win_xright_low =  rightx_current - window_width \n",
    "        win_xright_high = rightx_current + window_width  \n",
    "        \n",
    "        # Identify the pixels that are not zero within window\n",
    "        left_inds = ((nonzeroy >= win_y_low ) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        right_inds = ((nonzeroy >= win_y_low ) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # If more than minimum pixels are found -> recenter next window\n",
    "        if len(left_inds) > minimum_whites:\n",
    "            leftx_current = np.int(np.mean(nonzerox[left_inds]))\n",
    "            lefts_good = np.append(lefts_good, leftx_current)\n",
    "            if show_windows:\n",
    "                cv.rectangle(frame, (leftx_current - margin, win_y_low),(leftx_current + margin, win_y_high),(255, 255, 255), 2)\n",
    "        else:\n",
    "            lefts_good = np.append(lefts_good, None)\n",
    "        if len(right_inds) > minimum_whites:\n",
    "            rightx_current = np.int(np.mean(nonzerox[right_inds]))\n",
    "            rights_good = np.append(rights_good, rightx_current)\n",
    "            if show_windows:\n",
    "                cv.rectangle(frame, (rightx_current - margin, win_y_low),(rightx_current + margin, win_y_high),(255, 255, 255), 2)\n",
    "        else:\n",
    "            rights_good = np.append(rights_good, None)\n",
    "\n",
    "    return mid, lefts_good, rights_good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PolyLines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawPolyLines(frame, left_pts, right_pts):\n",
    "    y = np.linspace(len(frame), 0, nwindows+1).astype(int)\n",
    "    left_line = np.array(list(zip(left_pts[1:], y)))\n",
    "    right_line = np.array(list(zip(right_pts[1:], y)))\n",
    "\n",
    "    cv.polylines(frame, [left_line], 0, (255,255,255), 2)\n",
    "    cv.polylines(frame, [right_line], 0, (255,255,255), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time measure error: Event 'frame' not finished before reassignment!\n",
      "(628, 1212)\n",
      "(720, 1280, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eddi\\AppData\\Local\\Temp\\ipykernel_15820\\2659006520.py:8: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  mid = np.int(hist.shape[0] // 2)\n",
      "C:\\Users\\Eddi\\AppData\\Local\\Temp\\ipykernel_15820\\2659006520.py:12: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  window_height = np.int(frame.shape[0] // nwindows)\n",
      "C:\\Users\\Eddi\\AppData\\Local\\Temp\\ipykernel_15820\\2659006520.py:45: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  leftx_current = np.int(np.mean(nonzerox[left_inds]))\n",
      "C:\\Users\\Eddi\\AppData\\Local\\Temp\\ipykernel_15820\\2659006520.py:52: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  rightx_current = np.int(np.mean(nonzerox[right_inds]))\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) C:\\b\\abs_74oeeuevib\\croots\\recipe\\opencv-suite_1664548340488\\work\\modules\\core\\src\\arithm.cpp:650: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'cv::arithm_op'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Git\\Spurenerkennung\\main.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git/Spurenerkennung/main.ipynb#X15sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m \u001b[39mprint\u001b[39m(grayscale_frame\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git/Spurenerkennung/main.ipynb#X15sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m \u001b[39mprint\u001b[39m(orig\u001b[39m.\u001b[39mshape)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Git/Spurenerkennung/main.ipynb#X15sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m output \u001b[39m=\u001b[39m  cv\u001b[39m.\u001b[39;49maddWeighted(orig, \u001b[39m1\u001b[39;49m, grayscale_frame, \u001b[39m0.3\u001b[39;49m, \u001b[39m0\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git/Spurenerkennung/main.ipynb#X15sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m \u001b[39m# #treshhold for image\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git/Spurenerkennung/main.ipynb#X15sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m \u001b[39m# thresh = 160\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git/Spurenerkennung/main.ipynb#X15sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m \u001b[39m# ret, frame = cv.threshold(frame, thresh=thresh, maxval=255, type=cv.THRESH_BINARY)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git/Spurenerkennung/main.ipynb#X15sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git/Spurenerkennung/main.ipynb#X15sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m \u001b[39m# Add frame rate to video\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Git/Spurenerkennung/main.ipynb#X15sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m cv\u001b[39m.\u001b[39mputText(output, \u001b[39m\"\u001b[39m\u001b[39mFPS: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mround\u001b[39m(frame_rate)), (\u001b[39m0\u001b[39m, \u001b[39m25\u001b[39m),\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Git/Spurenerkennung/main.ipynb#X15sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m            cv\u001b[39m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[39m1\u001b[39m, (\u001b[39m255\u001b[39m, \u001b[39m255\u001b[39m, \u001b[39m0\u001b[39m), \u001b[39m2\u001b[39m, cv\u001b[39m.\u001b[39mLINE_AA,)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) C:\\b\\abs_74oeeuevib\\croots\\recipe\\opencv-suite_1664548340488\\work\\modules\\core\\src\\arithm.cpp:650: error: (-209:Sizes of input arguments do not match) The operation is neither 'array op array' (where arrays have the same size and the same number of channels), nor 'array op scalar', nor 'scalar op array' in function 'cv::arithm_op'\n"
     ]
    }
   ],
   "source": [
    "# Open video file\n",
    "video_file = \"project\"\n",
    "capture = cv.VideoCapture(\"./img/Udacity/\" + video_file + \"_video.mp4\")\n",
    "\n",
    "# Check if camera opened successfully\n",
    "if capture.isOpened() == False:\n",
    "    print(\"Error opening video stream or file\")\n",
    "\n",
    "# Start timer for fps counter\n",
    "start_timer = time.time() - 0.01\n",
    "frame_count = -1\n",
    "\n",
    "# Read every frame\n",
    "while capture.isOpened():\n",
    "    ret, frame = capture.read()\n",
    "\n",
    "    # Check if there is another frame\n",
    "    if frame is None:\n",
    "        break\n",
    "    orig = frame.copy()\n",
    "\n",
    "    # Calculate Frame rate\n",
    "    frame_count += 1\n",
    "    ellapsed_time = time.time() - start_timer\n",
    "    frame_rate = frame_count / ellapsed_time\n",
    "\n",
    "    if ret == True:\n",
    "        start_time_measurement(\"frame\")\n",
    "\n",
    "        frame = undistort_image_remap(frame)\n",
    "        frame = warp_image_udacity(frame)\n",
    "\n",
    "        #---------- Masking ----------\n",
    "        start_time_measurement(\"masking\")\n",
    "        ## convert to hsv\n",
    "        hls_frame = cv.cvtColor(frame, cv.COLOR_BGR2HLS)\n",
    "\n",
    "        ## mask for white\n",
    "        white_mask = cv.inRange(hls_frame, (0, 200, 0), (255, 255,255))\n",
    "\n",
    "        ## mask for yellow\n",
    "        # yellow_mask = cv.inRange(hls_frame, (20,90,200), (26, 255, 255))\n",
    "        yellow_mask = cv.inRange(hls_frame, (10,0,100), (40, 255, 255))\n",
    "\n",
    "        ## final mask and masked\n",
    "        mask = cv.bitwise_or(white_mask, yellow_mask)\n",
    "        frame = cv.bitwise_and(frame,frame, mask=mask)\n",
    "\n",
    "        end_time_measurement(\"masking\")\n",
    "        #---------- Filtering ----------\n",
    "        grayscale_frame = cv.cvtColor(frame, cv.COLOR_HLS2BGR)\n",
    "        grayscale_frame = cv.cvtColor(grayscale_frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "        # deblur image\n",
    "        # frame = cv.medianBlur(greyscale_frame,5)\n",
    "\n",
    "        #---------- Sliding Windows ----------\n",
    "        midpoint, lefts, rights = sliding_windows(grayscale_frame, minimum_whites=margin, show_windows=True)\n",
    "        # drawPolyLines(grayscale_frame, lefts, rights)\n",
    "        \n",
    "        #---------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "        #----------- rewarping ----------\n",
    "        start_time_measurement(\"rewarping\")\n",
    "        grayscale_frame = rewarp_image_udacity(grayscale_frame)\n",
    "        end_time_measurement(\"rewarping\")\n",
    "\n",
    "        #---------- combine ----------\n",
    "        \n",
    "\n",
    "        #---------- ----------\n",
    "        # #treshhold for image\n",
    "        # thresh = 160\n",
    "        # ret, frame = cv.threshold(frame, thresh=thresh, maxval=255, type=cv.THRESH_BINARY)\n",
    "\n",
    "        #deblur image\n",
    "        # frame = cv.medianBlur(frame,5)\n",
    "\n",
    "        # # Schärfungsfilter\n",
    "        # kernel2 = np.array([[-1,-1,-1],[-1,9,-1],[-1,-1,-1]],np.float32)\n",
    "        # frame = cv.filter2D(frame,-1,kernel2)\n",
    "\n",
    "        # wende Blurring an\n",
    "        # frame = cv.GaussianBlur(frame, (5, 5), cv.BORDER_DEFAULT)\n",
    "\n",
    "        # wende Canny Edge an\n",
    "        # frame = cv.Canny(frame, 50, 80)\n",
    "\n",
    "        # # Wende mophologische Filter(Closing und Opening) an\n",
    "        # small_kernel = np.array([[0,1,0],[1,1,1],[0,1,0]], 'uint8')\n",
    "        # frame = cv.morphologyEx(frame, cv.MORPH_CLOSE, small_kernel, iterations=20)\n",
    "\n",
    "        # frame = cv.morphologyEx(frame, cv.MORPH_OPEN, small_kernel, iterations=2)\n",
    "\n",
    "        # Add frame rate to video\n",
    "        cv.putText(grayscale_frame, \"FPS: \" + str(round(frame_rate)), (0, 25),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2, cv.LINE_AA,)\n",
    "        cv.imshow(\"Frame\", grayscale_frame)\n",
    "\n",
    "        end_time_measurement(\"frame\")\n",
    "\n",
    "        # Close video with letter 'q'\n",
    "        if cv.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# When everything done, release the video capture object\n",
    "capture.release()\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "analyse_time_measurements()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('Bildverarbeitung')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "acf0ef14ed89886f33db843bd70760c716ab8c7284b7e3a68e26cb56df8d4ac9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
