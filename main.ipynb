{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_measurements = {}\n",
    "\n",
    "def start_time_measurement(eventName):\n",
    "    if eventName not in time_measurements:\n",
    "        time_measurements[eventName] = {\n",
    "            \"name\": eventName,\n",
    "            \"start\": [time.process_time_ns()],\n",
    "            \"end\": []\n",
    "        }\n",
    "    elif len(time_measurements[eventName][\"start\"]) > len(time_measurements[eventName][\"end\"]):\n",
    "        print(f\"Time measure error: Event '{eventName}' not finished before reassignment!\")\n",
    "    else:\n",
    "       time_measurements[eventName][\"start\"].append(time.process_time_ns()) \n",
    "\n",
    "def end_time_measurement(eventName):\n",
    "    if eventName not in time_measurements:\n",
    "        print(f\"Time measure error: Event '{eventName}' not defined!\")\n",
    "    elif len(time_measurements[eventName][\"end\"]) >= len(time_measurements[eventName][\"start\"]):\n",
    "        print(f\"Time measure error: Event '{eventName}' not started before reassignment!\")\n",
    "    else:\n",
    "       time_measurements[eventName][\"end\"].append(time.process_time_ns()) \n",
    "\n",
    "def analyse_time_measurements():\n",
    "    for key, event in time_measurements.items():\n",
    "        if len(event[\"start\"]) != len(event[\"end\"]):\n",
    "            print(f\"Time measure error: Event '{key}' has different amounts of values for start and end times!\")\n",
    "        else:\n",
    "            event[\"avg\"] = sum((event[\"end\"][i] - event[\"start\"][i]) for i in range(len(event[\"start\"]))) / len(event[\"start\"])\n",
    "\n",
    "    # plt.boxplot([(i[\"end\"] - i[\"start\"])for i in list(time_measurements.values())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kamerakalibrierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of chessboard, minimum error with (7, 6), but there were severe artefacts at the borders (see error calculation at the end)\n",
    "x, y = 9, 6\n",
    "\n",
    "# termination criteria\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((y * x, 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:x, 0:y].T.reshape(-1, 2)\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = []  # 3d point in real world space\n",
    "imgpoints = []  # 2d points in image plane.\n",
    "\n",
    "\n",
    "images = glob.glob(\"./img/Udacity/calib/*.jpg\")\n",
    "for i, fname in enumerate(images):\n",
    "    img = cv.imread(fname)\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chess board corners\n",
    "    ret, corners = cv.findChessboardCorners(gray, (x, y), None)\n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        corners2 = cv.cornerSubPix(\n",
    "            gray, corners, (11, 11), (-1, -1), criteria\n",
    "        )  # improve accuracy of corners\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(\n",
    "    objpoints, imgpoints, gray.shape[::-1], None, None\n",
    ")\n",
    "\n",
    "h, w = img.shape[:2]\n",
    "newcameramtx, roi = cv.getOptimalNewCameraMatrix(mtx, dist, (w, h), 1, (w, h))\n",
    "\n",
    "\n",
    "def undistort_image(img):\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    img_undist = cv.undistort(img, mtx, dist, None, newcameramtx)\n",
    "    # crop the image\n",
    "    x, y, w, h = roi\n",
    "    return img_undist[y : y + h, x : x + w]\n",
    "\n",
    "\n",
    "# ~50% faster than undistort_image()\n",
    "def undistort_image_remap(img):\n",
    "    h, w = img.shape[:2]\n",
    "    mapx, mapy = cv.initUndistortRectifyMap(mtx, dist, None, newcameramtx, (w, h), 5)\n",
    "    dst = cv.remap(img, mapx, mapy, cv.INTER_LINEAR)\n",
    "    # crop the image\n",
    "    x, y, w, h = roi\n",
    "    return dst[y : y + h, x : x + w]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perspektivtransformation\n",
    "\n",
    "Mögliche Performance-verbesserung:\n",
    "\n",
    "- Bild nach warp verkleinern, da ein großteil des Bildes aus wenigen Pixeln entsteht ->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# udacity images\n",
    "src_udacity = np.float32([[191, 628], [531, 404], [1021, 628], [681, 404]])\n",
    "dst_udacity = np.float32([[150, 720], [150, 10], [1000, 720], [1000, 10]])\n",
    "M = cv.getPerspectiveTransform(src_udacity, dst_udacity)\n",
    "\n",
    "\n",
    "def warp_image_udacity(img):\n",
    "    image = cv.warpPerspective(img, M, (img.shape[1], img.shape[0]))\n",
    "    image = cv.resize(\n",
    "        image, (int(img.shape[1] / 2), int(img.shape[0] / 2))\n",
    "    )  # resize to half size\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sliding Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwindows = 50\n",
    "margin = 25\n",
    "def sliding_windows(frame, window_width=200, minimum_whites=30, show_windows=False):\n",
    "    # Histogram for image\n",
    "    hist = np.sum(frame[frame.shape[0]//2:, :], axis=0)\n",
    "        \n",
    "    # Take peaks from left and right side of histogramm for starting points and add half margin\n",
    "    mid = np.int(hist.shape[0] // 2)\n",
    "    leftx_start = np.argmax(hist[:mid]) - window_width // 2\n",
    "    rightx_start = np.argmax(hist[mid:]) + mid + window_width // 2\n",
    "    # Window height based on number of windows\n",
    "    window_height = np.int(frame.shape[0] // nwindows)\n",
    "    \n",
    "    # Calc points that are not zero in images\n",
    "    nonzero = frame.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    # Initialize current positions for windows\n",
    "    leftx_current = leftx_start\n",
    "    rightx_current = rightx_start\n",
    "\n",
    "    # Initialize values to be returned -> centers of windows\n",
    "    lefts_good = np.empty(shape=(1,1), dtype=int)\n",
    "    rights_good = np.empty(shape=(1,1), dtype=int)\n",
    "\n",
    "    # Go through every window\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = frame.shape[0] - (window + 1) * window_height\n",
    "        win_y_high = frame.shape[0] - window*window_height\n",
    "        \n",
    "        # Calculate boundaries of the window\n",
    "        win_xleft_low = leftx_current - window_width  \n",
    "        win_xleft_high = leftx_current + window_width  \n",
    "        win_xright_low =  rightx_current - window_width \n",
    "        win_xright_high = rightx_current + window_width  \n",
    "        \n",
    "        # Identify the pixels that are not zero within window\n",
    "        left_inds = ((nonzeroy >= win_y_low ) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        right_inds = ((nonzeroy >= win_y_low ) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # If more than minimum pixels are found -> recenter next window\n",
    "        if len(left_inds) > minimum_whites:\n",
    "            leftx_current = np.int(np.mean(nonzerox[left_inds]))\n",
    "            lefts_good = np.append(lefts_good, leftx_current)\n",
    "            if show_windows:\n",
    "                cv.rectangle(frame, (leftx_current - margin, win_y_low),(leftx_current + margin, win_y_high),(255, 255, 255), 2)\n",
    "        else:\n",
    "            lefts_good = np.append(lefts_good, None)\n",
    "        if len(right_inds) > minimum_whites:\n",
    "            rightx_current = np.int(np.mean(nonzerox[right_inds]))\n",
    "            rights_good = np.append(rights_good, rightx_current)\n",
    "            if show_windows:\n",
    "                cv.rectangle(frame, (rightx_current - margin, win_y_low),(rightx_current + margin, win_y_high),(255, 255, 255), 2)\n",
    "        else:\n",
    "            rights_good = np.append(rights_good, None)\n",
    "\n",
    "    return mid, lefts_good, rights_good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open video file\n",
    "video_file = \"project\"\n",
    "capture = cv.VideoCapture(\"./img/Udacity/\" + video_file + \"_video.mp4\")\n",
    "\n",
    "# Check if camera opened successfully\n",
    "if capture.isOpened() == False:\n",
    "    print(\"Error opening video stream or file\")\n",
    "\n",
    "# Start timer for fps counter\n",
    "start_timer = time.time() - 0.01\n",
    "frame_count = -1\n",
    "\n",
    "# Read every frame\n",
    "while capture.isOpened():\n",
    "    ret, frame = capture.read()\n",
    "\n",
    "    # Check if there is another frame\n",
    "    if frame is None:\n",
    "        break\n",
    "    orig = frame.copy()\n",
    "\n",
    "    # Calculate Frame rate\n",
    "    frame_count += 1\n",
    "    ellapsed_time = time.time() - start_timer\n",
    "    frame_rate = frame_count / ellapsed_time\n",
    "\n",
    "    if ret == True:\n",
    "\n",
    "        frame = undistort_image_remap(frame)\n",
    "        frame = warp_image_udacity(frame)\n",
    "\n",
    "        #---------- Masking ----------\n",
    "        ## convert to hsv\n",
    "        hls_frame = cv.cvtColor(frame, cv.COLOR_BGR2HLS)\n",
    "\n",
    "        ## mask for white\n",
    "        white_mask = cv.inRange(hls_frame, (0, 200, 0), (255, 255,255))\n",
    "\n",
    "        ## mask for yellow\n",
    "        # yellow_mask = cv.inRange(hls_frame, (20,90,200), (26, 255, 255))\n",
    "        yellow_mask = cv.inRange(hls_frame, (10,0,100), (40, 255, 255))\n",
    "\n",
    "        ## final mask and masked\n",
    "        mask = cv.bitwise_or(white_mask, yellow_mask)\n",
    "        frame = cv.bitwise_and(frame,frame, mask=mask)\n",
    "\n",
    "        #---------- Filtering ----------\n",
    "        greyscale_frame = cv.cvtColor(frame, cv.COLOR_HLS2BGR)\n",
    "        greyscale_frame = cv.cvtColor(greyscale_frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "        # deblur image\n",
    "        # frame = cv.medianBlur(greyscale_frame,5)\n",
    "        greyscale_frame = cv.Canny(greyscale_frame, 50, 150)\n",
    "\n",
    "        #---------- Sliding Windows ----------\n",
    "        # midpoint, lefts, rights = sliding_windows(frame, minimum_whites=margin, show_windows=True)\n",
    "        # window_height = np.int(frame.shape[0] // nwindows)\n",
    "        # for window in range(nwindows):\n",
    "        #     win_y_low = frame.shape[0] - (window + 1) * window_height\n",
    "        #     win_y_high = frame.shape[0] - window*window_height\n",
    "        #     if lefts[window]:\n",
    "        #         cv.rectangle(frame, (lefts[window] - margin, win_y_low),(lefts[window] + margin, win_y_high),(255, 255, 255), 2)\n",
    "        #     if rights[window]:\n",
    "        #         cv.rectangle(frame, (rights[window] - margin, win_y_low),(rights[window] + margin, win_y_high),(255, 255, 255), 2)\n",
    "\n",
    "        # y = np.linspace(len(frame), 0, nwindows+1).astype(int)\n",
    "        # left_line = np.array(list(zip(lefts[1:], y)))\n",
    "        # right_line = np.array(list(zip(rights[1:], y)))\n",
    "\n",
    "        # cv.polylines(frame, [left_line], 0, (255,255,255), 2)\n",
    "        # cv.polylines(frame, [right_line], 0, (255,255,255), 2)\n",
    "        #---------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "        # #treshhold for image\n",
    "        # thresh = 160\n",
    "        # ret, frame = cv.threshold(frame, thresh=thresh, maxval=255, type=cv.THRESH_BINARY)\n",
    "\n",
    "        #deblur image\n",
    "        # frame = cv.medianBlur(frame,5)\n",
    "\n",
    "        # # Schärfungsfilter\n",
    "        # kernel2 = np.array([[-1,-1,-1],[-1,9,-1],[-1,-1,-1]],np.float32)\n",
    "        # frame = cv.filter2D(frame,-1,kernel2)\n",
    "\n",
    "        # wende Blurring an\n",
    "        # frame = cv.GaussianBlur(frame, (5, 5), cv.BORDER_DEFAULT)\n",
    "\n",
    "        # wende Canny Edge an\n",
    "        # frame = cv.Canny(frame, 50, 80)\n",
    "\n",
    "        # # Wende mophologische Filter(Closing und Opening) an\n",
    "        # small_kernel = np.array([[0,1,0],[1,1,1],[0,1,0]], 'uint8')\n",
    "        # frame = cv.morphologyEx(frame, cv.MORPH_CLOSE, small_kernel, iterations=20)\n",
    "\n",
    "        # frame = cv.morphologyEx(frame, cv.MORPH_OPEN, small_kernel, iterations=2)\n",
    "\n",
    "        # Add frame rate to video\n",
    "        cv.putText(greyscale_frame, \"FPS: \" + str(round(frame_rate)), (0, 25),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2, cv.LINE_AA,)\n",
    "        cv.imshow(\"Frame\", greyscale_frame)\n",
    "\n",
    "        # Close video with letter 'q'\n",
    "        if cv.waitKey(15) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# When everything done, release the video capture object\n",
    "capture.release()\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3c5bf045d5047c0f00cfe2a5eb5fd13e5d63098e3da6354dfdacfff00d7c066"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
