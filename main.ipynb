{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_measurements = {}\n",
    "\n",
    "def start_time_measurement(eventName):\n",
    "    add = False\n",
    "    if eventName not in time_measurements:\n",
    "        time_measurements[eventName] = {\n",
    "            \"name\": eventName,\n",
    "            \"start\": [],\n",
    "            \"end\": [],\n",
    "            \"count\": 0\n",
    "        }\n",
    "        add = True\n",
    "    elif len(time_measurements[eventName][\"start\"]) > len(time_measurements[eventName][\"end\"]):\n",
    "        print(f\"Time measure error: Event '{eventName}' not finished before reassignment!\")\n",
    "    else:\n",
    "       add = True\n",
    "    \n",
    "    #start measurement as late as possible\n",
    "    if add:\n",
    "        time_measurements[eventName][\"start\"].append(time.perf_counter_ns())\n",
    "\n",
    "def end_time_measurement(eventName):\n",
    "    #end measurement as fast as possible\n",
    "    temp_time = time.perf_counter_ns()\n",
    "    if eventName not in time_measurements:\n",
    "        print(f\"Time measure error: Event '{eventName}' not defined!\")\n",
    "    elif len(time_measurements[eventName][\"end\"]) >= len(time_measurements[eventName][\"start\"]):\n",
    "        print(f\"Time measure error: Event '{eventName}' not started before reassignment!\")\n",
    "    else:\n",
    "        time_measurements[eventName][\"end\"].append(temp_time)\n",
    "        time_measurements[eventName][\"count\"] += 1\n",
    "\n",
    "def analyse_time_measurements():\n",
    "    time_measurements_table = PrettyTable([\"Name\", \"Avg. [ms]\", \"Min. [ms]\", \"Max. [ms]\", \"Occurrences [compl.]\"])\n",
    "    time_measurements_table.align[\"Name\"] = \"l\"\n",
    "    time_measurements_table.align[\"Avg. [ms]\"] = \"r\"\n",
    "    time_measurements_table.align[\"Min. [ms]\"] = \"r\"\n",
    "    time_measurements_table.align[\"Max. [ms]\"] = \"r\"\n",
    "    time_measurements_table.align[\"Occurrences [compl.]\"] = \"r\"\n",
    "    for key, event in time_measurements.items():\n",
    "        timings = []\n",
    "        if len(event[\"start\"]) != len(event[\"end\"]):\n",
    "            print(f\"Time measure error: Event '{key}' has different amounts of values for start and end times!\")\n",
    "        else:\n",
    "            #exclude 0 values\n",
    "            for i in range(len(event[\"start\"])):\n",
    "                timing = (event[\"end\"][i] - event[\"start\"][i])\n",
    "                if timing >= 0:\n",
    "                    timing = timing / (1000 * 1000) #convert from ns to ms\n",
    "                    timings.append(timing)\n",
    "\n",
    "            event[\"min\"] = min(timings) \n",
    "            event[\"max\"] = max(timings)\n",
    "            event[\"avg\"] = sum(timings) / len(event[\"start\"])\n",
    "\n",
    "            time_measurements_table.add_row([key, '{0:.2f}'.format(event[\"avg\"]), '{0:.2f}'.format(event[\"min\"]), '{0:.2f}'.format(event[\"max\"]), event[\"count\"]])\n",
    "    print(time_measurements_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kamerakalibrierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of chessboard, minimum error with (7, 6), but there were severe artefacts at the borders (see error calculation at the end)\n",
    "x, y = 9, 6\n",
    "\n",
    "# termination criteria\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((y * x, 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:x, 0:y].T.reshape(-1, 2)\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = []  # 3d point in real world space\n",
    "imgpoints = []  # 2d points in image plane.\n",
    "\n",
    "\n",
    "images = glob.glob(\"./img/Udacity/calib/*.jpg\")\n",
    "for i, fname in enumerate(images):\n",
    "    img = cv.imread(fname)\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chess board corners\n",
    "    ret, corners = cv.findChessboardCorners(gray, (x, y), None)\n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        corners2 = cv.cornerSubPix(\n",
    "            gray, corners, (11, 11), (-1, -1), criteria\n",
    "        )  # improve accuracy of corners\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(\n",
    "    objpoints, imgpoints, gray.shape[::-1], None, None\n",
    ")\n",
    "\n",
    "h, w = img.shape[:2]\n",
    "newcameramtx, roi = cv.getOptimalNewCameraMatrix(mtx, dist, (w, h), 1, (w, h))\n",
    "\n",
    "\n",
    "def undistort_image(img):\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    img_undist = cv.undistort(img, mtx, dist, None, newcameramtx)\n",
    "    # crop the image\n",
    "    x, y, w, h = roi\n",
    "    return img_undist[y : y + h, x : x + w]\n",
    "\n",
    "\n",
    "# ~50% faster than undistort_image()\n",
    "def undistort_image_remap(img):\n",
    "    h, w = img.shape[:2]\n",
    "    mapx, mapy = cv.initUndistortRectifyMap(mtx, dist, None, newcameramtx, (w, h), 5)\n",
    "    dst = cv.remap(img, mapx, mapy, cv.INTER_LINEAR)\n",
    "    # crop the image\n",
    "    x, y, w, h = roi\n",
    "    return dst[y : y + h, x : x + w]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perspektivtransformation\n",
    "\n",
    "Mögliche Performance-verbesserung:\n",
    "\n",
    "- Bild nach warp verkleinern, da ein großteil des Bildes aus wenigen Pixeln entsteht ->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# udacity images\n",
    "src_udacity = np.float32([[191, 628], [531, 404], [1021, 628], [681, 404]])\n",
    "dst_udacity = np.float32([[150, 720], [150, 10], [1000, 720], [1000, 10]])\n",
    "M_warp = cv.getPerspectiveTransform(src_udacity, dst_udacity)\n",
    "M_rewarp = cv.getPerspectiveTransform(dst_udacity, src_udacity)\n",
    "\n",
    "\n",
    "def warp_image_udacity(img):\n",
    "    img = cv.warpPerspective(img, M_warp, (img.shape[1], img.shape[0]))\n",
    "    # image = cv.resize(\n",
    "    #     image, (int(img.shape[1] / 2), int(img.shape[0] / 2))\n",
    "    # )  # resize to half size\n",
    "    return img\n",
    "\n",
    "def rewarp_image_udacity(img):\n",
    "    # image = cv.resize(\n",
    "    #     img, (int(img.shape[1] * 2), int(img.shape[0] * 2))\n",
    "    # ) \n",
    "    # img = cv.warpPerspective(img, M_rewarp, (img.shape[1], img.shape[0]))\n",
    "    img = cv.warpPerspective(img, M_rewarp, (img.shape[1], img.shape[0]), cv.WARP_INVERSE_MAP)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sliding Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwindows = 10\n",
    "margin = 50\n",
    "def sliding_windows(frame, window_width=200, minimum_whites=30, show_windows=False):\n",
    "    # Histogram for image\n",
    "    hist = np.sum(frame[frame.shape[0]//2:, :], axis=0)\n",
    "        \n",
    "    # Take peaks from left and right side of histogramm for starting points and add half margin\n",
    "    mid = np.int(hist.shape[0] // 2)\n",
    "    leftx_start = np.argmax(hist[:mid]) - window_width // 2\n",
    "    rightx_start = np.argmax(hist[mid:]) + mid + window_width // 2\n",
    "    # Window height based on number of windows\n",
    "    window_height = np.int(frame.shape[0] // nwindows)\n",
    "    \n",
    "    # Calc points that are not zero in images\n",
    "    nonzero = frame.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    # Initialize current positions for windows\n",
    "    leftx_current = leftx_start\n",
    "    rightx_current = rightx_start\n",
    "\n",
    "    # Initialize values to be returned -> centers of windows\n",
    "    lefts_good = np.empty(shape=(1,1), dtype=int)\n",
    "    rights_good = np.empty(shape=(1,1), dtype=int)\n",
    "\n",
    "    # Go through every window\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = frame.shape[0] - (window + 1) * window_height\n",
    "        win_y_high = frame.shape[0] - window*window_height\n",
    "        y_mid = (win_y_low + win_y_high) // 2\n",
    "        \n",
    "        # Calculate boundaries of the window\n",
    "        win_xleft_low = leftx_current - window_width  \n",
    "        win_xleft_high = leftx_current + window_width  \n",
    "        win_xright_low =  rightx_current - window_width \n",
    "        win_xright_high = rightx_current + window_width  \n",
    "        \n",
    "        # Identify the pixels that are not zero within window\n",
    "        left_inds = ((nonzeroy >= win_y_low ) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        right_inds = ((nonzeroy >= win_y_low ) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # If more than minimum pixels are found -> recenter next window\n",
    "        if len(left_inds) > minimum_whites:\n",
    "            leftx_current = np.int(np.mean(nonzerox[left_inds]))\n",
    "            lefts_good = np.append(lefts_good, leftx_current)\n",
    "            if show_windows:\n",
    "                cv.rectangle(frame, (leftx_current - margin, win_y_low),(leftx_current + margin, win_y_high),(255, 255, 255), 2)\n",
    "        else:\n",
    "            lefts_good = np.append(lefts_good, None)\n",
    "        if len(right_inds) > minimum_whites:\n",
    "            rightx_current = np.int(np.mean(nonzerox[right_inds]))\n",
    "            rights_good = np.append(rights_good, rightx_current)\n",
    "            if show_windows:\n",
    "                cv.rectangle(frame, (rightx_current - margin, win_y_low),(rightx_current + margin, win_y_high),(255, 255, 255), 2)\n",
    "        else:\n",
    "            rights_good = np.append(rights_good, None)\n",
    "\n",
    "    return mid, lefts_good, rights_good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PolyLines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawPolyLines(frame, left_pts, right_pts):\n",
    "    y = np.linspace(len(frame), 0, nwindows+1).astype(int)\n",
    "    left_line = np.array(list(zip(left_pts[1:], y)))\n",
    "    right_line = np.array(list(zip(right_pts[1:], y)))\n",
    "\n",
    "    cv.polylines(frame, [left_line], 0, (255,255,255), 2)\n",
    "    cv.polylines(frame, [right_line], 0, (255,255,255), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open video file\n",
    "video_file = \"project\"\n",
    "capture = cv.VideoCapture(\"./img/Udacity/\" + video_file + \"_video.mp4\")\n",
    "\n",
    "# Check if camera opened successfully\n",
    "if capture.isOpened() == False:\n",
    "    print(\"Error opening video stream or file\")\n",
    "\n",
    "# Start timer for fps counter\n",
    "start_timer = time.time() - 0.01\n",
    "frame_count = -1\n",
    "\n",
    "# Read every frame\n",
    "while capture.isOpened():\n",
    "    ret, frame = capture.read()\n",
    "\n",
    "    # Check if there is another frame\n",
    "    if frame is None:\n",
    "        break\n",
    "    orig = frame.copy()\n",
    "\n",
    "    # Calculate Frame rate\n",
    "    frame_count += 1\n",
    "    ellapsed_time = time.time() - start_timer\n",
    "    frame_rate = frame_count / ellapsed_time\n",
    "\n",
    "    if ret == True:\n",
    "        start_time_measurement(\"frame\")\n",
    "\n",
    "        frame = undistort_image_remap(frame)\n",
    "        orig_undist = frame.copy()\n",
    "        frame = warp_image_udacity(frame)\n",
    "\n",
    "        #---------- Masking ----------\n",
    "        start_time_measurement(\"masking\")\n",
    "        ## convert to hsv\n",
    "        hls_frame = cv.cvtColor(frame, cv.COLOR_BGR2HLS)\n",
    "\n",
    "        ## mask for white\n",
    "        white_mask = cv.inRange(hls_frame, (0, 200, 0), (255, 255,255))\n",
    "\n",
    "        ## mask for yellow\n",
    "        # yellow_mask = cv.inRange(hls_frame, (20,90,200), (26, 255, 255))\n",
    "        yellow_mask = cv.inRange(hls_frame, (10,0,100), (40, 255, 255))\n",
    "\n",
    "        ## final mask and masked\n",
    "        mask = cv.bitwise_or(white_mask, yellow_mask)\n",
    "        frame = cv.bitwise_and(frame,frame, mask=mask)\n",
    "\n",
    "        end_time_measurement(\"masking\")\n",
    "        #---------- Filtering ----------\n",
    "        grayscale_frame = cv.cvtColor(frame, cv.COLOR_HLS2BGR)\n",
    "        grayscale_frame = cv.cvtColor(grayscale_frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "        # deblur image\n",
    "        # frame = cv.medianBlur(greyscale_frame,5)\n",
    "\n",
    "        #---------- Sliding Windows ----------\n",
    "        midpoint, lefts, rights = sliding_windows(grayscale_frame, minimum_whites=margin, show_windows=True)\n",
    "        \n",
    "        y_values = np.linspace(len(img), 0, nwindows+1).astype(int)\n",
    "        # lefts = np.array(list(zip(lefts[1:], y_values)))\n",
    "        # rights = np.array(list(zip(rights[1:], y_values)))\n",
    "        # print(lefts)\n",
    "        # print(rights)\n",
    "        # print(midpoint)\n",
    "        # drawPolyLines(grayscale_frame, lefts, rights)\n",
    "        \n",
    "        #---------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "        # draw plane from all sliding windows\n",
    "        # contours, hierarchy = cv.findContours(grayscale_frame, cv.RETR_EXTERNAL , cv.CHAIN_APPROX_NONE)\n",
    "        # print(contours)\n",
    "        # break\n",
    "        # points = np.array([[[50,150],[130,100],[190,150],[170,270],[90,250]]], np.int32)\n",
    "        # cv.drawContours(grayscale_frame, [lefts], -1, (255,255,255), -1)\n",
    "        # for c in points:\n",
    "\n",
    "        #----------- rewarping ----------\n",
    "        start_time_measurement(\"rewarping\")\n",
    "        grayscale_frame = rewarp_image_udacity(grayscale_frame)\n",
    "        end_time_measurement(\"rewarping\")\n",
    "\n",
    "        #---------- combine ----------\n",
    "        \n",
    "        # grayscale to color\n",
    "        grayscale_frame = cv.cvtColor(grayscale_frame, cv.COLOR_GRAY2BGR)\n",
    "        def combine_two_color_images(image1, image2):\n",
    "\n",
    "            foreground, background = image1.copy(), image2.copy()\n",
    "            \n",
    "            foreground_height = foreground.shape[0]\n",
    "            foreground_width = foreground.shape[1]\n",
    "            alpha =0.5\n",
    "            \n",
    "            # do composite on the upper-left corner of the background image.\n",
    "            blended_portion = cv.addWeighted(foreground,\n",
    "                        alpha,\n",
    "                        background[:foreground_height,:foreground_width,:],\n",
    "                        1 - alpha,\n",
    "                        0,\n",
    "                        background)\n",
    "            background[:foreground_height,:foreground_width,:] = blended_portion\n",
    "            return background\n",
    "\n",
    "        out = combine_two_color_images(grayscale_frame, orig_undist)\n",
    "\n",
    "        #---------- ----------\n",
    "        # #treshhold for image\n",
    "        # thresh = 160\n",
    "        # ret, frame = cv.threshold(frame, thresh=thresh, maxval=255, type=cv.THRESH_BINARY)\n",
    "\n",
    "        #deblur image\n",
    "        # frame = cv.medianBlur(frame,5)\n",
    "\n",
    "        # # Schärfungsfilter\n",
    "        # kernel2 = np.array([[-1,-1,-1],[-1,9,-1],[-1,-1,-1]],np.float32)\n",
    "        # frame = cv.filter2D(frame,-1,kernel2)\n",
    "\n",
    "        # wende Blurring an\n",
    "        # frame = cv.GaussianBlur(frame, (5, 5), cv.BORDER_DEFAULT)\n",
    "\n",
    "        # wende Canny Edge an\n",
    "        # frame = cv.Canny(frame, 50, 80)\n",
    "\n",
    "        # # Wende mophologische Filter(Closing und Opening) an\n",
    "        # small_kernel = np.array([[0,1,0],[1,1,1],[0,1,0]], 'uint8')\n",
    "        # frame = cv.morphologyEx(frame, cv.MORPH_CLOSE, small_kernel, iterations=20)\n",
    "\n",
    "        # frame = cv.morphologyEx(frame, cv.MORPH_OPEN, small_kernel, iterations=2)\n",
    "\n",
    "        # Add frame rate to video\n",
    "        cv.putText(out, \"FPS: \" + str(round(frame_rate)), (0, 25),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2, cv.LINE_AA,)\n",
    "        cv.imshow(\"Frame\", out)\n",
    "\n",
    "        end_time_measurement(\"frame\")\n",
    "\n",
    "        # Close video with letter 'q'\n",
    "        if cv.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# When everything done, release the video capture object\n",
    "capture.release()\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "analyse_time_measurements()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
