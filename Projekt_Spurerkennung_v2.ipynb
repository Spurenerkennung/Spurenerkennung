{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a77db10",
   "metadata": {},
   "source": [
    "# Projekt: Erkennung von Spurmarkierungen\n",
    "\n",
    "In diesem Projekt sollen Spurmarkierungen in zwei bestehenden Datens√§tzen erkannt werden:\n",
    "\n",
    "1. Udacity Nanodegree \"Self-Driving Car Engineer\" (https://www.udacity.com/course/self-driving-car-engineer-nanodegree--nd0013)\n",
    "2. KITTI-Datensatz zur Erkennung von Spurmarkierungen (http://www.cvlibs.net/datasets/kitti/eval_road.php)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29415ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print('Willkommen beim Projekt \"Erkennung von Spurmarkierungen\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a530612a",
   "metadata": {},
   "source": [
    "# Exkurs 1: Kamerakalibrierung zur Entzerrung der Bilder\n",
    "\n",
    "Die vorhandenen Bilder sind aufgrund der Linsen- und Kameraeigenschaften verzerrt. Entzerren Sie die Bilder mithilfe der Kamerakalibrierungsroutinen von OpenCV (https://docs.opencv.org/4.5.3/dc/dbb/tutorial_py_calibration.html) und den aufgezeichneten Bildern.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9006c957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# einlesen eines Beispielbildes\n",
    "img1 = cv.cvtColor(cv.imread('./img/Udacity/calib/calibration1.jpg'), cv.COLOR_BGR2RGB)\n",
    "plt.imshow(img1)\n",
    "plt.title('Kalibrierungsbild')\n",
    "plt.show()\n",
    "\n",
    "# size of chessboard, minimum error with (7, 6), but there were severe artefacts at the borders (see error calculation at the end) \n",
    "x, y = 9, 6\n",
    "\n",
    "\n",
    "# termination criteria\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((y*x,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:x,0:y].T.reshape(-1,2)\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "\n",
    "images = glob.glob('./img/Udacity/calib/*.jpg')\n",
    "# images = ['./img/Udacity/calib/calibration1.jpg']\n",
    "plt.figure(figsize=(16,6))\n",
    "for i, fname in enumerate(images):\n",
    "    img = cv.imread(fname)\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Find the chess board corners\n",
    "    ret, corners = cv.findChessboardCorners(gray, (x,y), None)\n",
    "    # print(ret)\n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        corners2 = cv.cornerSubPix(gray,corners, (11,11), (-1,-1), criteria)\n",
    "        imgpoints.append(corners)\n",
    "        # Draw and display the corners\n",
    "        cv.drawChessboardCorners(img, (x,y), corners2, ret)\n",
    "        plt.subplot(4,5,i+1)\n",
    "        plt.imshow(img)\n",
    "        plt.xticks([]) \n",
    "        plt.yticks([])\n",
    "plt.show()\n",
    "\n",
    "ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "img = cv.imread('./img/Udacity/image001.jpg')\n",
    "img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "\n",
    "def undistort_image(img):\n",
    "    h,  w = img.shape[:2]\n",
    "    newcameramtx, roi = cv.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "\n",
    "    # undistort\n",
    "    img_undist = cv.undistort(img, mtx, dist, None, newcameramtx)\n",
    "    # crop the image\n",
    "    x, y, w, h = roi\n",
    "    return img_undist[y:y+h, x:x+w]\n",
    "\n",
    "img_undist = undistort_image(img)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img)\n",
    "plt.title('Image001')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(img_undist, cmap='gray')\n",
    "plt.title('Image001 undistorted')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# error calculation\n",
    "mean_error = 0\n",
    "for i in range(len(objpoints)):\n",
    "    imgpoints2, _ = cv.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist)\n",
    "    error = cv.norm(imgpoints[i], imgpoints2, cv.NORM_L2)/len(imgpoints2)\n",
    "    mean_error += error\n",
    "print( f\"total error: {mean_error/len(objpoints)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5135ced",
   "metadata": {},
   "source": [
    "Alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4177d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# einlesen eines Beispielbildes\n",
    "img1 = cv.cvtColor(cv.imread('./img/Udacity/calib/calibration1.jpg'), cv.COLOR_BGR2RGB)\n",
    "plt.imshow(img1)\n",
    "plt.title('Kalibrierungsbild')\n",
    "plt.show()\n",
    "\n",
    "width = 9\n",
    "height = 6\n",
    "\n",
    "# termination criteria\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((width*height,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[:width,:height].T.reshape(-1,2)\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "images = glob.glob('./img/Udacity/calib/*.jpg')\n",
    "for fname in images:\n",
    "    img = cv.imread(fname)\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    # Find the chess board corners\n",
    "    ret, corners = cv.findChessboardCorners(gray, (width, height), None, cv.CALIB_CB_ADAPTIVE_THRESH)\n",
    "    #ret, corners = cv.findChessboardCornersSB(gray, (6,5), None, cv.CALIB_CB_LARGER + cv.CALIB_CB_EXHAUSTIVE + cv.CALIB_CB_ACCURACY + cv.CALIB_CB_NORMALIZE_IMAGE)\n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        corners2 = cv.cornerSubPix(gray,corners, (11,11), (-1,-1), criteria)\n",
    "        imgpoints.append(corners)\n",
    "        #Draw and display the corners\n",
    "        cv.drawChessboardCorners(img, (width, height), corners2, ret)\n",
    "        cv.imshow('img', img)\n",
    "        cv.waitKey(500)\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "img = cv.imread('./img/Udacity/calib/calibration1.jpg')\n",
    "h,  w = img.shape[:2]\n",
    "newcameramtx, roi = cv.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "\n",
    "# undistort\n",
    "dst = cv.undistort(img, mtx, dist, None, newcameramtx)\n",
    "# crop the image\n",
    "x, y, w, h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "cv.imwrite('calibresult.png', dst)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img)\n",
    "plt.title(\"Original Kalibrierungsbild\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(dst)\n",
    "plt.title(\"Kalibrierungsbild mit undistort\")\n",
    "plt.show()\n",
    "\n",
    "# remap\n",
    "mapx, mapy = cv.initUndistortRectifyMap(mtx, dist, None, newcameramtx, (w,h), 5)\n",
    "dst = cv.remap(img, mapx, mapy, cv.INTER_LINEAR)\n",
    "# crop the image\n",
    "x, y, w, h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "cv.imwrite('calibresult.png', dst)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img)\n",
    "plt.title(\"Original Kalibrierungsbild\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(dst)\n",
    "plt.title(\"Kalibrierungsbild mit remap\")\n",
    "plt.show()\n",
    "\n",
    "mean_error = 0\n",
    "for i in range(len(objpoints)):\n",
    "    imgpoints2, _ = cv.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist)\n",
    "    error = cv.norm(imgpoints[i], imgpoints2, cv.NORM_L2)/len(imgpoints2)\n",
    "    mean_error += error\n",
    "print( \"total error: {}\".format(mean_error/len(objpoints)) )\n",
    "\n",
    "#----------Fahrspur undistort----------\n",
    "\n",
    "img = cv.imread('./img/Udacity/image001.jpg')\n",
    "img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "h,  w = img.shape[:2]\n",
    "newcameramtx, roi = cv.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "\n",
    "# undistort\n",
    "dst = cv.undistort(img, mtx, dist, None, newcameramtx)\n",
    "# crop the image\n",
    "x, y, w, h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "cv.imwrite('calibresult.png', dst)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img)\n",
    "plt.title(\"Original Lane-Img\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(dst)\n",
    "plt.title(\"Lane-Img mit undistort\")\n",
    "plt.show()\n",
    "\n",
    "#----------Fahrspur remap----------\n",
    "\n",
    "img = cv.imread('./img/Udacity/image001.jpg')\n",
    "img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "h,  w = img.shape[:2]\n",
    "newcameramtx, roi = cv.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "\n",
    "mapx, mapy = cv.initUndistortRectifyMap(mtx, dist, None, newcameramtx, (w,h), 5)\n",
    "dst = cv.remap(img, mapx, mapy, cv.INTER_LINEAR)\n",
    "# crop the image\n",
    "x, y, w, h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "cv.imwrite('calibresult.png', dst)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img)\n",
    "plt.title(\"Original Lane-Img\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(dst)\n",
    "plt.title(\"Lane-Img mit remap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65719edd",
   "metadata": {},
   "source": [
    "# Exkurs 2: Perspektivtransformation\n",
    "\n",
    "Durch die Kameraperspektive wird die Kr√ºmmung der gefundenen Spurmarkierungen nicht der realen Fahrstreifenkr√ºmmung entsprechen. Transformieren Sie daher die Bilder der Kameraperspektive in eine Vogelperspektive, die der realen Fahrstreifenkr√ºmmung entspricht.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4109f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# einlesen eines Beispielbildes\n",
    "img1 = cv.imread(\"img/Udacity/image001.jpg\", -1)\n",
    "img1 = img_undist\n",
    "# definieren Sie die f√ºr eine Perspektivtransformation notwendigen Quell- und Zielpunkte\n",
    "# pdf\n",
    "# src = np.array([[598, 448], [684, 448], [1026, 668], [278, 668]], np.float32)\n",
    "# dst = np.array([[300, 0], [980, 0], [980, 720], [300, 720]], np.float32)\n",
    "# gute\n",
    "# src = np.float32([[250, 600], [560, 400], [950, 600], [660, 400]])\n",
    "# dst = np.float32([[200, 720], [200, 10], [1000, 720], [1000, 10]])\n",
    "# besser (trapezform)\n",
    "# x = int(img1.shape[1]/2)\n",
    "# y = int(img1.shape[0]/2)\n",
    "# src = np.float32([[x-415, y*2], [x-75, y+90], [x+415, y*2], [x+75, y+90]])\n",
    "# dst = np.float32([[150, 720], [150, 10], [1000, 720], [1000, 10]])\n",
    "# fixwerte aus oberen, trapez in src\n",
    "src = np.float32([[191, 628], [531, 404], [1021, 628], [681, 404]])\n",
    "dst = np.float32([[150, 720], [150, 10], [1000, 720], [1000, 10]])\n",
    "\n",
    "for point in src:\n",
    "    plt.plot(point[0], point[1], marker=\"v\", color=\"red\")\n",
    "plt.imshow(img1)\n",
    "plt.title(\"Spurmarkierungen\")\n",
    "plt.show()\n",
    "\n",
    "M = cv.getPerspectiveTransform(src, dst)\n",
    "img1_warp = cv.warpPerspective(img1, M, (img1.shape[1], img1.shape[0]))\n",
    "for point in dst:\n",
    "    plt.plot(point[0], point[1], marker=\"v\", color=\"red\")\n",
    "plt.imshow(img1_warp)\n",
    "plt.show()\n",
    "\n",
    "# alle Bilder warpen\n",
    "images = glob.glob(\"./img/Udacity/*.jpg\")\n",
    "plt.figure(figsize=(30, 10))\n",
    "for index, image in enumerate(images):\n",
    "    img1 = undistort_image(cv.cvtColor(cv.imread(image, -1), cv.COLOR_BGR2RGB))\n",
    "    img1_warp = cv.warpPerspective(img1, M, (img1.shape[1], img1.shape[0]))\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.imshow(img1_warp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbd5355",
   "metadata": {},
   "source": [
    "# Aufgabe 3: Erkennung von Fahrbahnmarkierungen\n",
    "\n",
    "Erkennen Sie die Fahrbahnmarkierungen bzw. Fahrstreifen auf den Bildquellen von Udacity. Wenden Sie dabei die aus der Vorlesung bekannten Verfahren an. Gerne d√ºrfen Sie auch weitere Verfahren aus anderen Quellen verwenden. Folgende Ziele m√ºssen bei der finalen Abgabe erreicht werden:\n",
    "\n",
    "- **Segmentierung**: schr√§nken Sie das Bild auf den Bereich ein, in dem sich die Spurmarkierungen befinden\n",
    "- **Vorverarbeitung**: f√ºhren Sie eine Kamerakalibrierung (f√ºr Udacity-Bildquellen) und die Perspektivtransformation durch\n",
    "- **Farbr√§ume, Histogramme**: erkennen Sie die Spurmarkierungen in den Farben der angegebenen Quellen. Sofern weitere Spurmarkierungen auf dem Bild gefunden werden, m√ºssen diejenigen Spurmarkierungen priorisiert werden, die die eigene Fahrspur begrenzen\n",
    "- **Allgemeines**: Die Verarbeitung von Bildern muss in Echtzeit stattfinden --> Ziel: > 20 FPS\n",
    "- **Allgemeines**: Beschleunigen Sie die Verarbeitung durch weitere Ma√ünahmen weitere Ma√ünahmen √ºberlegen (bspw. Erkennung der Spurmarkierung in den ersten Frames, Tracking der Spurmarkierung in weiteren Frames solange, bis sich Spurmarkierungspositionen zu stark √§ndern)\n",
    "- **Minimal**: relevante Spurmarkierungen werden im Video \"project_video\" durchgehend erkannt\n",
    "- **Zusatz**: relevante Spurmarkierungen werden im Video \"challenge_video\" und \"harder_challenge_video\" durchgehend erkannt\n",
    "- **Zusatz**: relevante Spurmarkierungen werden auf den Datensatz KITTI angewendet. Welche Anpassungen m√ºssen vorgenommen werden, damit Ihr Algorithmus √ºbertragen werden kann?\n",
    "- **Zusatz**: Erarbeiten Sie weitere Ma√ünahmen zur Geschwindigkeitsverbesserung Ihres Algorithmus\n",
    "- **Zusatz**: Erkennen Sie Objekte im Bild und visualisieren Sie diese (z.B. weitere Fahrzeuge, Motorr√§der, etc.)\u000bDie Objekterkennung bitte so implementieren, dass sie deaktivierbar ist und nicht in FPS-Berechnung einzahlt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a3f53c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3ade8db",
   "metadata": {},
   "source": [
    "# Ausblick auf weitere Teilaufgaben\n",
    "\n",
    "- Bestimmung der Kurvenkr√ºmmung anhand von Polynom-Fiting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5f6feb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
