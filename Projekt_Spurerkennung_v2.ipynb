{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a77db10",
   "metadata": {},
   "source": [
    "# Projekt: Erkennung von Spurmarkierungen\n",
    "In diesem Projekt sollen Spurmarkierungen in zwei bestehenden Datensätzen erkannt werden: \n",
    "1. Udacity Nanodegree \"Self-Driving Car Engineer\" (https://www.udacity.com/course/self-driving-car-engineer-nanodegree--nd0013)\n",
    "2. KITTI-Datensatz zur Erkennung von Spurmarkierungen (http://www.cvlibs.net/datasets/kitti/eval_road.php)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29415ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print('Willkommen beim Projekt \"Erkennung von Spurmarkierungen\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a530612a",
   "metadata": {},
   "source": [
    "# Exkurs 1: Kamerakalibrierung zur Entzerrung der Bilder\n",
    "Die vorhandenen Bilder sind aufgrund der Linsen- und Kameraeigenschaften verzerrt. Entzerren Sie die Bilder mithilfe der Kamerakalibrierungsroutinen von OpenCV (https://docs.opencv.org/4.5.3/dc/dbb/tutorial_py_calibration.html) und den aufgezeichneten Bildern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9006c957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# einlesen eines Beispielbildes\n",
    "img1 = cv.cvtColor(cv.imread('./img/Udacity/calib/calibration1.jpg'), cv.COLOR_BGR2RGB)\n",
    "plt.imshow(img1)\n",
    "plt.title('Kalibrierungsbild')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65719edd",
   "metadata": {},
   "source": [
    "# Exkurs 2: Perspektivtransformation\n",
    "Durch die Kameraperspektive wird die Krümmung der gefundenen Spurmarkierungen nicht der realen Fahrstreifenkrümmung entsprechen. Transformieren Sie daher die Bilder der Kameraperspektive in eine Vogelperspektive, die der realen Fahrstreifenkrümmung entspricht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4109f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# einlesen eines Beispielbildes\n",
    "img1 = cv.imread('./img/Udacity/image001.jpg', -1)\n",
    "plt.imshow(cv.cvtColor(img1, cv.COLOR_BGR2RGB))\n",
    "plt.title('Spurmarkierungen')\n",
    "plt.show()\n",
    "\n",
    "# definieren Sie die für eine Perspektivtransformation notwendigen Quell- und Zielpunkte\n",
    "src = np.float32(...)\n",
    "dst = np.float32(...)\n",
    "\n",
    "M = cv.getPerspectiveTransform(src,dst)\n",
    "img1_warp = cv.warpPerspective(img1,M,(img1.shape[1], img1.shape[0]))\n",
    "plt.imshow(cv.cvtColor(img1_warp, cv.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbd5355",
   "metadata": {},
   "source": [
    "# Aufgabe 3: Erkennung von Fahrbahnmarkierungen\n",
    "Erkennen Sie die Fahrbahnmarkierungen bzw. Fahrstreifen auf den Bildquellen von Udacity. Wenden Sie dabei die aus der Vorlesung bekannten Verfahren an. Gerne dürfen Sie auch weitere Verfahren aus anderen Quellen verwenden. Folgende Ziele müssen bei der finalen Abgabe erreicht werden: \n",
    "- **Segmentierung**: schränken Sie das Bild auf den Bereich ein, in dem sich die Spurmarkierungen befinden\n",
    "- **Vorverarbeitung**: führen Sie eine Kamerakalibrierung (für Udacity-Bildquellen) und die Perspektivtransformation durch\n",
    "- **Farbräume, Histogramme**: erkennen Sie die Spurmarkierungen in den Farben der angegebenen Quellen. Sofern weitere Spurmarkierungen auf dem Bild gefunden werden, müssen diejenigen Spurmarkierungen priorisiert werden, die die eigene Fahrspur begrenzen\n",
    "- **Allgemeines**: Die Verarbeitung von Bildern muss in Echtzeit stattfinden --> Ziel: > 20 FPS\n",
    "- **Allgemeines**: Beschleunigen Sie die Verarbeitung durch weitere Maßnahmen weitere Maßnahmen überlegen (bspw. Erkennung der Spurmarkierung in den ersten Frames, Tracking der Spurmarkierung in weiteren Frames solange, bis sich Spurmarkierungspositionen zu stark ändern)\n",
    "- **Minimal**: relevante Spurmarkierungen werden im Video \"project_video\" durchgehend erkannt \n",
    "- **Zusatz**: relevante Spurmarkierungen werden im Video \"challenge_video\" und \"harder_challenge_video\" durchgehend erkannt\n",
    "- **Zusatz**: relevante Spurmarkierungen werden auf den Datensatz KITTI angewendet. Welche Anpassungen müssen vorgenommen werden, damit Ihr Algorithmus übertragen werden kann?\n",
    "- **Zusatz**: Erarbeiten Sie weitere Maßnahmen zur Geschwindigkeitsverbesserung Ihres Algorithmus\n",
    "- **Zusatz**: Erkennen Sie Objekte im Bild und visualisieren Sie diese (z.B. weitere Fahrzeuge, Motorräder, etc.)\u000bDie Objekterkennung bitte so implementieren, dass sie deaktivierbar ist und nicht in FPS-Berechnung einzahlt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a3f53c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3ade8db",
   "metadata": {},
   "source": [
    "# Ausblick auf weitere Teilaufgaben\n",
    "- Bestimmung der Kurvenkrümmung anhand von Polynom-Fiting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5f6feb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('Bildverarbeitung')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "be9dc93785d85ace52bcadbf19d950224dbeb77b6ec1b22f2b51edc757959746"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
