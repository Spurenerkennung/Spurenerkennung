{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a77db10",
   "metadata": {},
   "source": [
    "# Projekt: Erkennung von Spurmarkierungen\n",
    "\n",
    "In diesem Projekt sollen Spurmarkierungen in zwei bestehenden Datensätzen erkannt werden:\n",
    "\n",
    "1. Udacity Nanodegree \"Self-Driving Car Engineer\" (https://www.udacity.com/course/self-driving-car-engineer-nanodegree--nd0013)\n",
    "2. KITTI-Datensatz zur Erkennung von Spurmarkierungen (http://www.cvlibs.net/datasets/kitti/eval_road.php)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29415ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print('Willkommen beim Projekt \"Erkennung von Spurmarkierungen\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a530612a",
   "metadata": {},
   "source": [
    "# Exkurs 1: Kamerakalibrierung zur Entzerrung der Bilder\n",
    "\n",
    "Die vorhandenen Bilder sind aufgrund der Linsen- und Kameraeigenschaften verzerrt. Entzerren Sie die Bilder mithilfe der Kamerakalibrierungsroutinen von OpenCV (https://docs.opencv.org/4.5.3/dc/dbb/tutorial_py_calibration.html) und den aufgezeichneten Bildern.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9006c957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# einlesen eines Beispielbildes\n",
    "img1 = cv.cvtColor(cv.imread('./img/Udacity/calib/calibration1.jpg'), cv.COLOR_BGR2RGB)\n",
    "plt.imshow(img1)\n",
    "plt.title('Kalibrierungsbild')\n",
    "plt.show()\n",
    "\n",
    "# size of chessboard, minimum error with (7, 6), but there were severe artefacts at the borders (see error calculation at the end) \n",
    "x, y = 9, 6\n",
    "\n",
    "\n",
    "# termination criteria\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((y*x,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:x,0:y].T.reshape(-1,2)\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "\n",
    "images = glob.glob('./img/Udacity/calib/*.jpg')\n",
    "# images = ['./img/Udacity/calib/calibration1.jpg']\n",
    "plt.figure(figsize=(16,6))\n",
    "for i, fname in enumerate(images):\n",
    "    img = cv.imread(fname)\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Find the chess board corners\n",
    "    ret, corners = cv.findChessboardCorners(gray, (x,y), None)\n",
    "    # print(ret)\n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        corners2 = cv.cornerSubPix(gray,corners, (11,11), (-1,-1), criteria)\n",
    "        imgpoints.append(corners)\n",
    "        # Draw and display the corners\n",
    "        cv.drawChessboardCorners(img, (x,y), corners2, ret)\n",
    "        plt.subplot(4,5,i+1)\n",
    "        plt.imshow(img)\n",
    "        plt.xticks([]) \n",
    "        plt.yticks([])\n",
    "plt.show()\n",
    "\n",
    "ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "img = cv.imread('./img/Udacity/image001.jpg')\n",
    "img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "\n",
    "def undistort_image(img):\n",
    "    h,  w = img.shape[:2]\n",
    "    newcameramtx, roi = cv.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "\n",
    "    # undistort\n",
    "    img_undist = cv.undistort(img, mtx, dist, None, newcameramtx)\n",
    "    # crop the image\n",
    "    x, y, w, h = roi\n",
    "    return img_undist[y:y+h, x:x+w]\n",
    "\n",
    "img_undist = undistort_image(img)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img)\n",
    "plt.title('Image001')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(img_undist, cmap='gray')\n",
    "plt.title('Image001 undistorted')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# error calculation\n",
    "mean_error = 0\n",
    "for i in range(len(objpoints)):\n",
    "    imgpoints2, _ = cv.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist)\n",
    "    error = cv.norm(imgpoints[i], imgpoints2, cv.NORM_L2)/len(imgpoints2)\n",
    "    mean_error += error\n",
    "print( f\"total error: {mean_error/len(objpoints)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5135ced",
   "metadata": {},
   "source": [
    "Alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4177d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# einlesen eines Beispielbildes\n",
    "img1 = cv.cvtColor(cv.imread('./img/Udacity/calib/calibration1.jpg'), cv.COLOR_BGR2RGB)\n",
    "plt.imshow(img1)\n",
    "plt.title('Kalibrierungsbild')\n",
    "plt.show()\n",
    "\n",
    "width = 9\n",
    "height = 6\n",
    "\n",
    "# termination criteria\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((width*height,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[:width,:height].T.reshape(-1,2)\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "images = glob.glob('./img/Udacity/calib/*.jpg')\n",
    "for fname in images:\n",
    "    img = cv.imread(fname)\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    # Find the chess board corners\n",
    "    ret, corners = cv.findChessboardCorners(gray, (width, height), None, cv.CALIB_CB_ADAPTIVE_THRESH)\n",
    "    #ret, corners = cv.findChessboardCornersSB(gray, (6,5), None, cv.CALIB_CB_LARGER + cv.CALIB_CB_EXHAUSTIVE + cv.CALIB_CB_ACCURACY + cv.CALIB_CB_NORMALIZE_IMAGE)\n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        corners2 = cv.cornerSubPix(gray,corners, (11,11), (-1,-1), criteria)\n",
    "        imgpoints.append(corners)\n",
    "        #Draw and display the corners\n",
    "        cv.drawChessboardCorners(img, (width, height), corners2, ret)\n",
    "        cv.imshow('img', img)\n",
    "        cv.waitKey(500)\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "img = cv.imread('./img/Udacity/calib/calibration1.jpg')\n",
    "h,  w = img.shape[:2]\n",
    "newcameramtx, roi = cv.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "\n",
    "# undistort\n",
    "dst = cv.undistort(img, mtx, dist, None, newcameramtx)\n",
    "# crop the image\n",
    "x, y, w, h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "cv.imwrite('calibresult.png', dst)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img)\n",
    "plt.title(\"Original Kalibrierungsbild\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(dst)\n",
    "plt.title(\"Kalibrierungsbild mit undistort\")\n",
    "plt.show()\n",
    "\n",
    "# remap\n",
    "mapx, mapy = cv.initUndistortRectifyMap(mtx, dist, None, newcameramtx, (w,h), 5)\n",
    "dst = cv.remap(img, mapx, mapy, cv.INTER_LINEAR)\n",
    "# crop the image\n",
    "x, y, w, h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "cv.imwrite('calibresult.png', dst)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img)\n",
    "plt.title(\"Original Kalibrierungsbild\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(dst)\n",
    "plt.title(\"Kalibrierungsbild mit remap\")\n",
    "plt.show()\n",
    "\n",
    "mean_error = 0\n",
    "for i in range(len(objpoints)):\n",
    "    imgpoints2, _ = cv.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist)\n",
    "    error = cv.norm(imgpoints[i], imgpoints2, cv.NORM_L2)/len(imgpoints2)\n",
    "    mean_error += error\n",
    "print( \"total error: {}\".format(mean_error/len(objpoints)) )\n",
    "\n",
    "#----------Fahrspur undistort----------\n",
    "\n",
    "img = cv.imread('./img/Udacity/image001.jpg')\n",
    "img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "h,  w = img.shape[:2]\n",
    "newcameramtx, roi = cv.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "\n",
    "# undistort\n",
    "dst = cv.undistort(img, mtx, dist, None, newcameramtx)\n",
    "# crop the image\n",
    "x, y, w, h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "cv.imwrite('calibresult.png', dst)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img)\n",
    "plt.title(\"Original Lane-Img\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(dst)\n",
    "plt.title(\"Lane-Img mit undistort\")\n",
    "plt.show()\n",
    "\n",
    "#----------Fahrspur remap----------\n",
    "\n",
    "img = cv.imread('./img/Udacity/image001.jpg')\n",
    "img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "h,  w = img.shape[:2]\n",
    "newcameramtx, roi = cv.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "\n",
    "mapx, mapy = cv.initUndistortRectifyMap(mtx, dist, None, newcameramtx, (w,h), 5)\n",
    "dst = cv.remap(img, mapx, mapy, cv.INTER_LINEAR)\n",
    "# crop the image\n",
    "x, y, w, h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "cv.imwrite('calibresult.png', dst)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img)\n",
    "plt.title(\"Original Lane-Img\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(dst)\n",
    "plt.title(\"Lane-Img mit remap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65719edd",
   "metadata": {},
   "source": [
    "# Exkurs 2: Perspektivtransformation\n",
    "\n",
    "Durch die Kameraperspektive wird die Krümmung der gefundenen Spurmarkierungen nicht der realen Fahrstreifenkrümmung entsprechen. Transformieren Sie daher die Bilder der Kameraperspektive in eine Vogelperspektive, die der realen Fahrstreifenkrümmung entspricht.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4109f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# einlesen eines Beispielbildes\n",
    "img1 = cv.imread(\"img/Udacity/image001.jpg\", -1)\n",
    "img1 = img_undist\n",
    "# definieren Sie die für eine Perspektivtransformation notwendigen Quell- und Zielpunkte\n",
    "# pdf\n",
    "# src = np.array([[598, 448], [684, 448], [1026, 668], [278, 668]], np.float32)\n",
    "# dst = np.array([[300, 0], [980, 0], [980, 720], [300, 720]], np.float32)\n",
    "# gute\n",
    "# src = np.float32([[250, 600], [560, 400], [950, 600], [660, 400]])\n",
    "# dst = np.float32([[200, 720], [200, 10], [1000, 720], [1000, 10]])\n",
    "# besser (trapezform)\n",
    "# x = int(img1.shape[1]/2)\n",
    "# y = int(img1.shape[0]/2)\n",
    "# src = np.float32([[x-415, y*2], [x-75, y+90], [x+415, y*2], [x+75, y+90]])\n",
    "# dst = np.float32([[150, 720], [150, 10], [1000, 720], [1000, 10]])\n",
    "# fixwerte aus oberen, trapez in src\n",
    "src = np.float32([[191, 628], [531, 404], [1021, 628], [681, 404]])\n",
    "dst = np.float32([[150, 720], [150, 10], [1000, 720], [1000, 10]])\n",
    "\n",
    "for point in src:\n",
    "    plt.plot(point[0], point[1], marker=\"v\", color=\"red\")\n",
    "plt.imshow(img1)\n",
    "plt.title(\"Spurmarkierungen\")\n",
    "plt.show()\n",
    "\n",
    "M = cv.getPerspectiveTransform(src, dst)\n",
    "img1_warp = cv.warpPerspective(img1, M, (img1.shape[1], img1.shape[0]))\n",
    "for point in dst:\n",
    "    plt.plot(point[0], point[1], marker=\"v\", color=\"red\")\n",
    "plt.imshow(img1_warp)\n",
    "plt.show()\n",
    "\n",
    "# alle Bilder warpen\n",
    "images = glob.glob(\"./img/Udacity/*.jpg\")\n",
    "plt.figure(figsize=(30, 10))\n",
    "for index, image in enumerate(images):\n",
    "    img1 = undistort_image(cv.cvtColor(cv.imread(image, -1), cv.COLOR_BGR2RGB))\n",
    "    img1_warp = cv.warpPerspective(img1, M, (img1.shape[1], img1.shape[0]))\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.imshow(img1_warp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbd5355",
   "metadata": {},
   "source": [
    "# Aufgabe 3: Erkennung von Fahrbahnmarkierungen\n",
    "\n",
    "Erkennen Sie die Fahrbahnmarkierungen bzw. Fahrstreifen auf den Bildquellen von Udacity. Wenden Sie dabei die aus der Vorlesung bekannten Verfahren an. Gerne dürfen Sie auch weitere Verfahren aus anderen Quellen verwenden. Folgende Ziele müssen bei der finalen Abgabe erreicht werden:\n",
    "\n",
    "- **Segmentierung**: schränken Sie das Bild auf den Bereich ein, in dem sich die Spurmarkierungen befinden\n",
    "- **Vorverarbeitung**: führen Sie eine Kamerakalibrierung (für Udacity-Bildquellen) und die Perspektivtransformation durch\n",
    "- **Farbräume, Histogramme**: erkennen Sie die Spurmarkierungen in den Farben der angegebenen Quellen. Sofern weitere Spurmarkierungen auf dem Bild gefunden werden, müssen diejenigen Spurmarkierungen priorisiert werden, die die eigene Fahrspur begrenzen\n",
    "- **Allgemeines**: Die Verarbeitung von Bildern muss in Echtzeit stattfinden --> Ziel: > 20 FPS\n",
    "- **Allgemeines**: Beschleunigen Sie die Verarbeitung durch weitere Maßnahmen weitere Maßnahmen überlegen (bspw. Erkennung der Spurmarkierung in den ersten Frames, Tracking der Spurmarkierung in weiteren Frames solange, bis sich Spurmarkierungspositionen zu stark ändern)\n",
    "- **Minimal**: relevante Spurmarkierungen werden im Video \"project_video\" durchgehend erkannt\n",
    "- **Zusatz**: relevante Spurmarkierungen werden im Video \"challenge_video\" und \"harder_challenge_video\" durchgehend erkannt\n",
    "- **Zusatz**: relevante Spurmarkierungen werden auf den Datensatz KITTI angewendet. Welche Anpassungen müssen vorgenommen werden, damit Ihr Algorithmus übertragen werden kann?\n",
    "- **Zusatz**: Erarbeiten Sie weitere Maßnahmen zur Geschwindigkeitsverbesserung Ihres Algorithmus\n",
    "- **Zusatz**: Erkennen Sie Objekte im Bild und visualisieren Sie diese (z.B. weitere Fahrzeuge, Motorräder, etc.)\u000bDie Objekterkennung bitte so implementieren, dass sie deaktivierbar ist und nicht in FPS-Berechnung einzahlt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a3f53c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3ade8db",
   "metadata": {},
   "source": [
    "# Ausblick auf weitere Teilaufgaben\n",
    "\n",
    "- Bestimmung der Kurvenkrümmung anhand von Polynom-Fiting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5f6feb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
